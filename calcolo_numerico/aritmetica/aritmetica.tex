\section{Aritmetica di macchina}
Adesso rimane da capire come la macchina mappa i numeri reali in numeri di macchina. Il problema che ci
poniamo è il seguente: sia $x \in \R$, quale numero di macchina $\tilde{x} \in \F$ viene associato a $x$
per la rappresentazione?

Associare un numero di macchina $\tilde{x}$ a $x$ significa \textbf{approssimare} $x$ commettendo un
\textbf{errore relativo} di rappresentazione
\[ \epsilon_x = \frac{\tilde{x} - x}{x} = \frac{\eta_x}{x}, \quad x \neq 0 \]
quanto più piccolo possibile in valore assoluto. La quantità
\[ \eta_x = \tilde{x} - x \]
è detta \textbf{errore assoluto} di rappresentazione. Dato $x \in \R$ con $x \neq 0$, distinguiamo 2 casi:
\begin{itemize}
	\item $|x| < \omega$ (\textbf{underflow}) o $|x| > \Omega$ (\textbf{overflow})
	\item $\omega \leq |x| \leq \Omega$
\end{itemize}
Nel secondo caso le tecniche di approssimazione previste dallo standard IEEE 754 sono:
\begin{itemize}
	\item \textbf{Round to the nearest} (arrotondamento): il numero $x$ viene approssimato con il numero di
	      macchina $\tilde{x}$ più vicino.
	\item \textbf{Round toward zero} (troncamento): il numero $x$ viene approssimato con il più grande numero
	      di macchina $\tilde{x}$ il cui valore assoluto risulti minore o uguale al valore assoluto di $x$.
	\item \textbf{Round toward plus infinity}: il numero $x$ viene approssimato al più piccolo numero
	      rappresentabile maggiore del dato.
	\item \textbf{Round toward minus infinity}: il numero $x$ viene approssimato al più grande numero
	      rappresentabile minore del dato.
\end{itemize}
Assumiamo per semplicità di considerare una macchina che opera con troncamento sull'insieme $\F$. Per
convenzione indichiamo con $\trn(x) = \tilde{x}$ il risultato dell'approssimazione di $x$ con troncamento e
più generalmente $\fl(x)$ l'approssimazione in macchina del dato $x$ nel sistema \emph{floating point}
considerato. Il primo risultato fornisce una maggiorazione uniforme dell'errore di rappresentazione.

\begin{theorem}\label{th: prec}
	Sia $x \in \R$ con $\omega \leq |x| \leq \Omega$. Si ha
	\[ |\epsilon_x| = \left| \frac{\trn(x) - x}{x} \right| \leq u = B^{1-t} \]
	dove $u$ è detta \textbf{precisione di macchina}, la quale non dipende da $x$ e fornisce errori più grandi
	per numeri grandi ed errori piccoli per numeri piccoli.
	\begin{proof}
		Sia $x = (-1)^s \cdot B^p \alpha$. L'errore assoluto $|\trn(x) - x|$ risulta maggiorato dalla distanza
		tra i due numeri di macchina consecutivi e quindi
		\[ |\trn(x) - x| \leq B^{p-t} \]
		Inoltre $|x| \geq B^{p-1}$. Pertanto vale
		\[ |\epsilon_x| = \left| \frac{\trn(x) - x}{x} \right| \leq \frac{B^{p-t}}{B^{p-1}} = B^{1-t} = u \]
	\end{proof}
\end{theorem}

\begin{observation}
	Possiamo osservare che
	\begin{itemize}
		\item La \emph{precisione di macchina} è indipendente dalla grandezza del numero e caratteristica
		      dell'aritmetica \emph{floating point} implementata sulla macchina su cui stiamo operando. Se ad
		      esempio operiamo con arrotondamento, la distanza tra $x$ e la sua approssimazione di macchina, e
		      quindi la precisione di macchina, si dimezzano.
		\item Per valutare la precisione di macchina possiamo determinare il più piccolo numero di macchina
		      maggiore di 1. Sia infatti $x$ il numero che cerchiamo, abbiamo che $x - 1 = |x - 1| = B^{1-t}$,
		      essendo $1 = B^1 \cdot B^{-1}$ rappresentato con esponente $p = 1$.
		\item Dal teorema \ref{th: prec} si ricava che, dato $x \in \R$, in assenza di situazione di
		      \emph{underflow} o \emph{overflow}, per la sua rappresentazione in macchina vale che
		      \[ \fl(x) = x (1 + \epsilon_x), \quad |\epsilon_x| \leq u \]
		      Questa relazione esprime il modo in cui viene generalmente descritto il legame tra un numero reale
		      e la sua rappresentazione in macchina.
	\end{itemize}
\end{observation}

\subsection{Operazioni aritmetiche}
Per le operazioni aritmetiche eseguite in un sistema \emph{floating point} si pone un analogo problema di
approssimazione in quanto il risultato dell'operazione tra due numeri di macchina, in generale, non sarà
un numero di macchina.

Introduciamo dunque una variante delle quattro operazioni fondamentali che indichiamo con $\oplus$, $\ominus$,
$\otimes$ e $\oslash$. Per tali operazioni è ovviamente richiesto che siano interne all'insieme dei numeri
di macchina e che producano un'approssimazione quanto più accurata del risultato esatto.

Prendiamo ad esempio l'operazione di addizione in macchina. Un possibile implementazione è la seguente
\[ \tilde{x} \oplus \tilde{y} = \trn(\tilde{x} + \tilde{y}) \]
Qui usiamo il troncamento per semplicità ma in realtà l'arrotondamento è il metodo più usato in quanto fornisce
maggiore accuratezza per l'approssimazione. L'operazione scritta sopra produrrà quindi un errore di
approssimazione, il quale viene chiamato \textbf{errore di rappresentazione locale} dell'operazione.

\begin{example}
	Supponiamo di voler calcolare la quantità $f(x) = \frac{x - 1}{x}$. \`E immediato accorgersi che
	\[ \frac{x - 1}{x} = x - \frac{1}{x} \]
	E dunque già si identificano due possibile strade per il calcolo della quantità ma concentriamoci solo
	sulla prima per il momento.

	La prima cosa che fa la macchina è mappare $x$ in $\tilde{x}$. A questo dobbiamo stare molto attenti in
	quanto l'algoritmo girerà con
	\[ \tilde{x} = x (1 + \epsilon_x), \quad |\epsilon_x| \leq u \]
	e non con $x$, fornendo un risultato potenzialmente del tutto sbagliato.

	La cifra 1 la possiamo assumere come numero di macchina in quanto ogni sistema ragionevole include 1 tra
	i numeri di macchina.

	Se siamo molto fortunati calcolaremo esattamente $f(\tilde{x})$ ma la maggior parte delle volte non sarà
	così e ne calcolaremo un'approssimazione
	\[ g(\tilde{x}) = \frac{\tilde{x} \ominus 1}{\tilde{x}} \]
	Dunque calcoliamo una funzione di fatto differente dalla prima. Sviluppiando l'espressione otteniamo
	\begin{align*}
		g(\tilde{x})  = & \frac{\tilde{x} \ominus 1}{\tilde{x}}                                                \\
		=               & \frac{x (1 + \epsilon_x) \ominus 1}{x (1 + \epsilon_x)}                              \\
		=               & \frac{[x (1 + \epsilon_x) - 1](1 + \epsilon_1)}{x (1 + \epsilon_x)} (1 + \epsilon_2)
	\end{align*}
	Dove $\epsilon_x \leq u$, $\epsilon_1 \leq u$ e $\epsilon_2 \leq 2$.
\end{example}