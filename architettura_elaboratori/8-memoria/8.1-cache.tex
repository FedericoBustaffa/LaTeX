\chapter{Memoria}
Fino ad ora abbiamo parlato di \textbf{memoria} considerandola quasi come un modulo interno alla
ma come abbiamo visto all'inizio del corso nel modello Von Neumann, la memoria è un qualcosa di
esterno che comunica con il processore.

Nel tempo c'è stata una rapida evoluzione delle $\mu$-architetture dei processori con conseguente
aumento delle prestazioni. Sebbene anche le memorie si siano evolute non si può dire che siano
riuscite a reggere il confronto.

Sempre come abbiamo visto nello schema iniziale del modello Von Neumann, un divario di prestazioni
tra CPU e memoria, va a creare quello che prende il nome di \textbf{Von Neumann bottleneck} che
rallenta anche le prestazioni del processore.

Questo perché per quanto il nostro processore sia prestante, se non riusciamo a leggere e scrivere
la memoria altrettanto velocemente, non riusciremo a sfruttare a pieno le potenzialità del
processore.

Quando abbiamo parlato di memoria abbiamo fatto distinzione tra \textbf{registri}, come latch, flip
flop, registri da 1 bit e così via. Quelle che vogliamo trattare ora sono le \textbf{memorie} che
in precedenza abbiamo distinto tra \emph{statiche} (array di registri) e \emph{dinamche} (array di
transistor).

Quello che vogliamo fare è sostanzialmente definire un \textbf{sistema di memoria} composto in
maniera gerarchica
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.9]{circuiti/memorie.svg}
\end{center}
Come possiamo vedere abbiamo inserito un elemento di cui non avevamo mai parlato prima, ovvero la
\textbf{cache} che, come vedremo ci aiuterà ad agevolare le interazioni con la memoria.

\section{Cache}
La memoria \textbf{cache} è una memoria piccola e molto veloce anche se non quanto i registri.
Ci serve per memorizzare le istruzioni o i dati che soddisfano due criteri fondamentali:
\begin{itemize}
	\item \textbf{Località spaziale}: se accediamo una locazione di memoria è molto probabile che
	      accederemo nel breve periodo anche le locazioni vicine.
	\item \textbf{Località temporale}: se accediamo una locazione di memoria al tempo $t_0$ è molto
	      probabile che ad un certo tempo $t_k$, con $k$ piccolo, acceda nuovamente alla stessa
	      locazione di memoria.
\end{itemize}
La cache non fa parte dello schema che di solito facciamo per la $\mu$-architettura di un
processore ma fa comunque parte della CPU. Possiamo infatti definire un ulteriore schema gerarchico
di cache in questo modo
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.7]{circuiti/cache_gen.svg}
\end{center}
Come possiamo vedere abbiamo tre livelli di cache, il primo livello è diviso in cache per le
istruzioni e cache per i dati. Ora però dobbiamo capire come
\begin{enumerate}
	\item Muovere i dati tra i vari livelli della gerarchia.
	\item Trovare i dati nella cache dato che non possiamo aspettarci di trovarli allo stesso
	      indirizzo che usavamo per reperire i dati in RAM.
\end{enumerate}
Iniziamo con il risolvere il secondo problema, capendo prima di tutto come è fatta una cache.
Possiamo vedere la cache come un insieme di \textbf{linee} o \textbf{blocchi}, ognuna composta da
più campi ma divisa in due parti principali:
\begin{itemize}
	\item L'ultima parte composta da un certo numero di parole.
	\item La prima parte composta da informazioni riguardanti tali parole.
\end{itemize}
Supponendo di avere una cache capace di memorizzare $n \cdot k$ parole e composta da $k$ linee,
ciascuna da $n$ parole. Il risultato sarebbe una cache in cui ogni linea è composta da un campo
\textbf{tag} (che approfondiremo più avanti), $\log_2 (\# \text{blocchi})$ bit rappresentanti il
numero di linea e $\log_2 (n)$ bit che rappresentano un offset, necessario a scegliere una delle
$n$ parole nella linea. L'ultima parte della linea, come già detto, è composta dalle $n$ parole.

\subsection{Indirizzamento diretto}
Supponiamo di avere un programma \verb|main| caricato in memoria principale e supponiamo di
disporre di una cache da 4 linee, ciascuna in grado di memorizzare 4 parole.

Abbiamo quindi che ogni linea della cache ha una prima parte composta da 28 bit di \emph{tag}, 2
bit per l'identificazione del numero di linea e 2 bit per l'offset.
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.8] {circuiti/cache_word.svg}
\end{center}

Se ora effettuiamo il fetch della prima istruzione di \verb|main|, per i criteri di località
precedentemente descritti, vorremmo memorizzare nella cache, non solo tale istruzione ma anche le
successive 3, dato che in una linea della cache possiamo inserire 4 istruzioni.

Per capire dove memorizzare queste parole nella cache utilizziamo il loro indirizzo e per ognuna di
esse andiamo a vedere i 2 bit che indicano il numero di linea (supponiamo siano 01 per tutte e 4
le parole) e gli ultimi 2 bit (da 00 a 11) per andare a trovare la colonna corretta.
\begin{center}
	\includesvg[inkscapelatex=false, scale=0.8]{circuiti/cache_load.svg}
\end{center}
Il campo \emph{tag} viene riempito con i primi 28 bit di \verb|main + 0| e inoltre si aggiunge un
\textbf{bit di presenza} o \textbf{validità} per capire se il contenuto della linea è significativo
o meno.

Se ora eseguissimo il fetch di \verb|main + 1|, leggeremmo che gli ultimi 4 bit sono 0101, il che
significa che dobbiamo andare a leggere la cache nella linea 1 con un offset di 1 per ottenere
\verb|main + 1|. Se il tag della linea corrisponde al tag dell'indirizzo allora possiamo usare il
valore trovato. Per recuperare dati da una cache il procedimento prevede quindi di
\begin{enumerate}
	\item Usare il numero di blocco dell'indirizzo per accedere alla linea corretta.
	\item Confrontare i tag dell'indirizzo e della linea.
	\item Se i tag corrispondono si usa l'offset per ricavare la parola.
\end{enumerate}
Detto così non è molto chiaro il perché si debba usare un tag.