\chapter{Riduzione a scalini}
\section{Operazioni elementari sulle colonne}
Consideriamo una generica matrice in $\Mat{m \times n}(\K)$:
\[
	A = \begin{pmatrix}
		a_{11} & a_{12} & \dots & a_{1n} \\
		a_{21} & a_{22} & \dots & \dots  \\
		\dots  & \dots  & \dots & \dots  \\
		a_{m1} & \dots  & \dots & a_{mn}
	\end{pmatrix}
\]
e i tre seguenti tipi di mossa sulle colonne, detti anche
\textbf{operazioni elementari sulle colonne}:
\begin{enumerate}
	\item si somma alla colonna $i$ la colonna $j$ moltiplicata per uno scalare
	      $\lambda$.
	\item si moltiplica la colonna $i$ per uno scalare $\lambda$
	\item si scambiano fra di loro due colonne $i$ e $j$.
\end{enumerate}

\begin{definition}
	La \textbf{profondità} di una colonna è definita come la posizione
	occupata (contata dal basso) dal suo più alto coefficiente diverso da 0.
	Alla colonna nulla si assegna per convenzione profondità uguale a 0.
\end{definition}

\begin{example}
	Consideriamo la seguente matrice:
	\[
		A = \begin{pmatrix}
			0            & 4 - \sqrt{3} & 0  \\
			\sqrt{3} + 1 & 0            & 0  \\
			-2           & -2           & -2
		\end{pmatrix}
	\]
	In questo caso la prima colonna ha profodità uguale a 2, la
	seconda colonna uguale a 3 mentre la terza ha profondità uguale a 1.
\end{example}

\begin{definition}
	Una matrice $A \in \Mat{m \times n}(\K)$, si dice
	\textbf{in forma a scalini per colonne} se rispetta le seguenti proprietà:
	\begin{itemize}
		\item leggendo la matrice da sinistra a destra, le colonne non nulle si
		      incontrano tutte prima delle colonne nulle.
		\item leggendo la matrice da sinistra a destra, le profondità
		      delle sue colonne non nulle risultano strettamente
		      decrescenti.
	\end{itemize}
\end{definition}

\begin{example}
	Questi sono esempi di matrici in forma \emph{a scalini}:
	\[
		A = \begin{pmatrix}
			1            & 0           & 0 & 0 \\
			\sqrt{3} + 1 & 1           & 0 & 0 \\
			-2           & \frac{5}{2} & 1 & 0
		\end{pmatrix}
	\]
	\[
		B = \begin{pmatrix}
			1  & 0           & 0 & 0 \\
			0  & 1           & 0 & 0 \\
			-2 & \frac{5}{2} & 0 & 0
		\end{pmatrix}
	\]
\end{example}

\begin{definition}
	In una matrice in forma a scalini per colonna, i coefficienti diversi
	da zero più alti di posizione di ogni colonna non nulla si
	chiamano \textbf{pivot}.
\end{definition}

\begin{theorem}
	Data una matrice $A \in \Mat{m \times n}(\K)$ è sempre
	possibile, usando operazioni elementari sulle colonne, ridurre la
	matrice in forma a scalini per colonne.
\end{theorem}

\begin{observation}
	Quando si riduce una matrice in forma a scalini, la forma a scalini
	ottenuta non è unica.
\end{observation}

\begin{definition}
	Una matrice $A \in \Mat{m \times n}(\K)$, si dice \textbf{in forma a
		scalini per colonne ridotta} se:
	\begin{itemize}
		\item $A$ è a scalini per colonne.
		\item Tutte le entrate nella stessa riga di un pivot, precedenti al pivot,
		      sono nulle
	\end{itemize}
\end{definition}

\begin{example}
	Esempio di matrice in forma a scalini ridotta:
	\[
		\begin{pmatrix}
			1            & 0           & 0 & 0 \\
			\sqrt{3} + 1 & 1           & 0 & 0 \\
			-2           & \frac{5}{2} & 1 & 0
		\end{pmatrix} \rightarrow
		\begin{pmatrix}
			1 & 0 & 0 & 0 \\
			0 & 1 & 0 & 0 \\
			0 & 0 & 1 & 0
		\end{pmatrix}
	\]
\end{example}

\begin{proposition}
	Data una matrice in forma a scalini per colonne, è sempre possibile, usando
	solo la prima delle operazioni elementari sulle colonne, portare $A$ in forma
	a scalini ridotta.
\end{proposition}

\begin{corollary}
	Ogni matrice $A$ può essere trasformata, tramite le operazioni elementari
	sulle colonne, in una matrice in forma a scalini per colonne ridotta.
\end{corollary}

\begin{proposition}
	Se operiamo attraverso le operazioni elementari sulle colonne, lo
	$Span$ dei vettori colonna rimane invariato. Ovvero se indichiamo con
	$v_1, \dots, v_n$ i vettori colonna di una matrice
	$A \in \Mat{m \times n}(\K)$, per ogni matrice $A'$ ottenuta da $A$
	attraverso le operazioni elementari sulle colonne, si ha, indicando con
	$w_1, \dots, w_n$ i vettori colonna di $A'$, che:
	\[
		Span(v_1, \dots, v_n) = Span(w_1, \dots, w_n)
	\]
\end{proposition}

\section{Riduzione a scalini e studio delle basi}

\begin{theorem}
	Sia $V$ uno spazio vettoriale su $\K$ che ammette una base
	finita, allora tutte le basi di $V$ hanno la stessa cardinalità.
\end{theorem}

\begin{corollary}
	In uno spazio vettoriale $V$ di dimensione $n$, dati $n$ vettori
	linearmente indipendenti questi sono anche una base di $V$. Allo
	stesso modo, dati $n$ vettori che generano $V$, questi sono anche una
	base di $V$.
\end{corollary}

Considerzioni simili a quelle fatte fino ad ora ci consentono di descrivere
un criterio concreto per decidere se, dato uno spazio vettoriale $V$ di
dimensione $n$ ed una base $e_1, \dots, e_n$ di $V$, e dati $n$ vettori
$v_1, \dots, v_n$ di $V$, tali vettori costituiscono una base di $V$ o no.

Il criterio è espresso dai seguenti punti:
\begin{enumerate}
	\item Esprimiamo i vettori $v_1, \dots, v_n$ trovandone i coefficienti rispetto
	      alla base $e_1, \dots, e_n$.
	\item Poniamoli in colonna uno accanto all'altro. Così facendo otteniamo una
	      matrice $M$ che è $n \times n$.
	\item Riduciamo $M$ in forma a scalini ridotta ottenendo $M'$.
	\item A questo punto, se $M'$ è l'identità, allora $\{v_1, \dots, v_n\}$
	      è una base di $V$, altrimenti no.
\end{enumerate}

\begin{example}
	Verificare che i seguenti vettori siano una base di $\R^4$.
	\[
		v_1 = \begin{pmatrix}
			1 \\ 1 \\ 0 \\ 0
		\end{pmatrix} \quad
		v_2 = \begin{pmatrix}
			0 \\ 1 \\ 1 \\ 0
		\end{pmatrix} \quad
		v_3 = \begin{pmatrix}
			0 \\ 0 \\ 1 \\ 1
		\end{pmatrix} \quad
		v_4 = \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 1
		\end{pmatrix}
	\]
	Verifichiamo col nuovo metodo che si tratta di una base.
	Scriviamo dunque la matrice
	\[
		\begin{pmatrix}
			1 & 0 & 0 & 0 \\
			1 & 1 & 0 & 0 \\
			0 & 1 & 1 & 0 \\
			0 & 0 & 1 & 1 \\
		\end{pmatrix}
	\]
	Portandola in forma a scalini ridotta diventa
	\[
		\begin{pmatrix}
			1 & 0 & 0 & 0 \\
			0 & 1 & 0 & 0 \\
			0 & 0 & 1 & 0 \\
			0 & 0 & 0 & 1
		\end{pmatrix}
	\]
	Dunque $\{v_1, v_2, v_3, v_4\}$ è una base di $\R^4$.
\end{example}

\begin{theorem}[Completamento]
	Dato uno spazio vettoriale $V$ di dimensione $n$, ogni
	sottoinsieme $B = \{v_1, \dots, v_k\} \subset V$ di vettori
	linearmente indipendenti di cardinalità $k$, con
	$1 \leq k \leq n$, può essere completato ad una base di $V$
	aggiungendo a $B$ $n - k$ vettori di $V \backslash Span(B)$.
	\begin{proof}
		La dimostrazione che segue ci fornisce un algoritmo per trovare
		vettori da aggiungere al sottoinsieme $B$ per riuscire a trovare
		una base di $V$.
		\begin{enumerate}
			\item Si scrivono i vettori $v_1, \dots, v_k$ come
			      vettori colonna rispetto a una base data, e si considera
			      la matrice $M$ che ha questi vettori come colonne.
			\item Si riduce $M$ in forma a scalini.
			\item Tutte le volte le volte che troviamo uno scalino lungo
			      (altezza $\geq 2$, dove l'altezza è la differenza di profondità
			      tra due colonne adiacenti che formano lo scalino lungo) possiamo
			      facilmente trovare $i - 1$ vettori $w_1, \dots, w_{i - 1}$ tali che
			      $\{v_1, \dots, v_k, w_1, \dots, w_{i - 1}\}$ è ancora un
			      insieme di vettori linearmente indipendenti.
			\item Supponiamo infatti che $M$ abbia uno scalino di lunghezza $i$,
			      ovvero in una certa colonna abbia il pivot alla riga $t$ e nella
			      colonna successiva alla riga $t+i$, e sia $i > 1$. Allora
			      per $j$ che varia tra 1 ed $i - 1$.
			\item Scegliere un vettore $w_j$ tale che abbia tutti
			      0 tranne un 1 in corrispondeza della riga $(t + j)$-esima.
			      È facile osservare che ogni $w_j$ non appartiene
			      allo $Span(v_1, \dots, v_k, w_1, \dots, w_{j-1})$. Dunque ad
			      ogni aggiunta di $w_j$, l'insieme
			      $\{v_1, \dots, v_k, w_1, \dots, w_j\}$ rimane un insieme di
			      vettori linearmente indipendenti di $V$.
			\item Ripetiamo questa aggiunta di vettori $w_k$ per ogni scalino
			      lungo che troviamo in $M$, trovando così alla fine $n$ vettori
			      linearmente indipendenti, dunque una base di $V$ come richiesto.
		\end{enumerate}
	\end{proof}
\end{theorem}

\begin{example}
	Illustriamo il metodo descritto con un esempio. Supponiamo che
	$V = \R^7$ e siano dati i 4 vettori linearmente
	indipendenti che, scritti rispetto alla base standard di
	$\R^7$, sono rappresentati come segue:
	\[
		v_1 = \begin{pmatrix}
			1 \\ 1 \\ 0 \\ 2 \\ 1 \\ 0 \\ 1
		\end{pmatrix} \quad
		v_2 = \begin{pmatrix}
			0 \\ 1 \\ 0 \\ 2 \\ 1 \\ 0 \\ 3
		\end{pmatrix} \quad
		v_3 = \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 0 \\ 1 \\ 0 \\ 1
		\end{pmatrix} \quad
		v_4 = \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 0 \\ 1 \\ 0 \\ 2
		\end{pmatrix}
	\]
	La matrice $M$ in questo caso è:
	\[
		M = \begin{pmatrix}
			1 & 0 & 0 & 0 \\
			1 & 1 & 0 & 0 \\
			0 & 0 & 0 & 0 \\
			2 & 2 & 0 & 0 \\
			1 & 1 & 1 & 1 \\
			0 & 0 & 0 & 0 \\
			1 & 3 & 1 & 2
		\end{pmatrix}
	\]
	Riduciamola a scalini per colonne.
	\[
		M' = \begin{pmatrix}
			1 & 0 & 0 & 0 \\
			0 & 1 & 0 & 0 \\
			0 & 0 & 0 & 0 \\
			0 & 2 & 0 & 0 \\
			1 & 0 & 1 & 0 \\
			0 & 0 & 0 & 0 \\
			0 & 1 & 2 & 1
		\end{pmatrix}
	\]
	Il primo scalino lungo ha altezza 3. Come osservato nella dimostrazione
	del teorema del completamento, i vettori
	\[
		w_1 = \begin{pmatrix}
			0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0
		\end{pmatrix} \quad
		w_2 = \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0
		\end{pmatrix}
	\]
	non appartengono al sottospazio generato dalle colonne di $M'$, e si
	osserva immediatamente che $\{v_1, v_2, v_3, v_4, w_1, w_2\}$ è un
	insieme di vettori linearmente indipendenti di $\R^7$.

	Similmente prendendo in considerazione il secondo scalino lungo, notiamo
	che il vettore
	\[
		w_3 = \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 1 \\ 0
		\end{pmatrix}
	\]
	non appartiene al sottospazio generato da $v_1, v_2, v_3, v_4, w_1, w_2$.

	A questo punto abbiamo ottenuto l'insieme di vettori linearmente indipendenti
	$\{v_1, v_2, v_3, v_4, w_1, w_2, w_3\}$ di $\R^7$ e dato che
	$\R^7$ ha dimensione 7 abbiamo ottenuto una base di $\R^7$.
\end{example}


\section{Il teorema della dimensione del nucleo e dell'immagine di una applicazione lineare}
Il teorema del completamento, ha come importante corollario un risultato che stabilisce
una relazione tra la dimensione del nucleo e quella dell'immagine di una applicazione
lineare.

\begin{theorem}
	Considerata una applicazione lineare $L : V \to W$, dove $V$ e $W$ sono spazi
	vettoriali su $\K$, vale
	\[
		\dim(\Ker(L)) + \dim(\Imm(L)) = \dim(V)
	\]
\end{theorem}

\begin{definition}
	Una applicazione lineare bigettiva $L : V \to W$, tra due spazi vettoriali $V$ e $W$
	sul campo $\K$, si dice un \textbf{isomorfismo lineare}.

	Dal teorema precedente segue che:
	\begin{itemize}
		\item Se $L : V \to W$ è una applicazione lineare iniettiva allora
		      \[ \dim(\Imm(L)) = \dim(V) \]
		      Infatti sappiamo che $\Ker(L) = \{O\}$ dunque $\dim(\Ker(L)) = 0$.
		\item Se $L : V \to W$ è un isomorfismo lineare allora \[\dim(V) = \dim(W)\]
		      Infatti se $L$ è bigettiva, in particolare è iniettiva e surgettiva.
		\item Se $L : V \to W$ è una applicazione lineare iniettiva, allora $L$,
		      pensata come applicazione da $V$ ad $\Imm(L)$, è un isomorfismo lineare.
	\end{itemize}
\end{definition}

\section{immagine di un'applicazione lineare}
La riduzione a scalini per colonna risulta molto utile anche per lo
studio di applicazioni lineari, ed in particolare per la
determinazione di dimensione e base dell'immagine di una applicazione
lineare.

Dati due spazi vettoriali $V$ e $W$ sul campo $\K$ di dimensione $n$
e $m$ rispettivamente, consideriamo una applicazione lineare:
\[
	L : V \to W
\]
Fissiamo una base $\{e_1, e_2, \dots, e_n\}$ di $V$ e una base
$\{\epsilon_1, \epsilon_2, \dots, \epsilon_m\}$ di $W$. Indichiamo con $[L]$
la matrice, di forma $m \times n$, associata a $L$ nelle basi scelte.

Per quanto abbiamo fin qui detto, possiamo, tramite un numero finito $k$ di
operazioni elementari sulle colonne di $[L]$, portarla in forma a scalini
ridotta. Ma c'è di più. Ogni operazione elementare sulle colonne corrisponde
a moltiplicare la matrice iniziale $[L] \in \Mat{m \times n}(\K)$,
a destra, per una matrice $B$ di dimensioni $n \times n$ invertibile.

\begin{theorem}
	Siano $V, W, U$ spazi vettoriali su $\K$, fissiamo per ciascuno
	una base. Siano $T : V \to W$ e $S : W \to U$ applicazioni lineari. Allora,
	rispetto alle basi fissate, vale:
	\[
		[S \circ T] = [S][T]
	\]
	dove nel membro di destra stiamo considerando il prodotto righe per colonne
	fra matrici.
\end{theorem}

Tornando all'applicazione lineare $L$, sappiamo già che lo span delle colonne
di $[L]$ coincide con lo span delle colonne della matrice ottenuta portando $[L]$
in forma a scalini. Sappiamo cioè che $\Imm(L)$ coincide con l'immagine
dell'applicazione lineare associata alla matrice ottenuta portando i forma a
scalini $[L]$.

\begin{proposition}
	Siano $L$ ed $M$ due applicazioni lineari, vale
	\[ \Imm(L \circ M) = \Imm(L) \]
	ossia, scritto con un'altra notazione,
	\[ (L \circ M)(V) = L(V) \]
\end{proposition}

\begin{proposition}
	Sia $B : V \to V$ un'applicazione lineare invertibile, allora vale
	\[ \Imm(L) = \Imm(L \circ B) \]
	\begin{proof}
		Dato che $B$ è una funzione invertibile, è bigettiva, ossia
		\[ B(V) = V \]. Dunque
		\[
			\Imm(L \circ B) = L(B(V)) = L(V)
		\]
	\end{proof}
\end{proposition}

\begin{definition}
	Data una applicazione lineare $L : V \to W$, dove $V$ e $W$ sono due spazi
	vettoriali di dimensione finita sul campo $\K$ e sia $[L]$ la matrice
	associata ad $L$. Se riduco in forma a scalini $[L]$, il \textbf{rango} equivale
	al numero di pivot della matrice ottenuta.
\end{definition}

\begin{theorem}
	Data una applicazione lineare $L$ come sopra e fissate le basi, vale che
	il rango di $L$ è uguale al numero di colonne non nulle che si trovano
	quando si trasforma $[L]$ in forma a scalini.
\end{theorem}

\begin{observation}
	Osserviamo che il rango di una applicazione lineare $L$ è anche uguale al
	\textbf{massimo numero di colonne linearmente indipendenti} di $[L]$.
	Infatti sappiamo che $\Imm(L)$ è il sottospazio vettoriale di $W$ generato
	dai vettori colonna di $[L]$. Da questi vettori è possibile estrarre una
	base di $\Imm(L)$ e, inoltre, possiamo dire che \[\dim(\Imm(L)) = rango (L)\]
\end{observation}

\begin{observation}
	Possiamo ora definire un algoritmo in 3 passi che, data una
	applicazione lineare tra due spazi vettoriali $V$ e $W$, e fissata una base
	$\{e_1, e_2, \dots, e_n\}$ di $V$ e una base
	$\{\epsilon_1, \epsilon_2, \dots, \epsilon_m\}$ di $W$, ci permette di
	determinare la dimensione ed una base di $\Imm(L)$:
	\begin{enumerate}
		\item Scrivere la matrice $[L]$ associata ad $L$ rispetto alle basi
		      fissate
		\item Ridurre $[L]$ in forma a scalini
		\item Contare il numero di pivot per ottenere la dimensione di $\Imm(L)$.
	\end{enumerate}
\end{observation}

\section{Riduzione a scalini per righe}
Data una matrice in $\Mat{m \times n}(\K)$ è possibile definire le
operazioni elementari di riga in modo analogo alle mosse di colonna in questo
modo:
\begin{enumerate}
	\item Sommare alla riga $i$ la riga $j$ moltiplicata per uno scalare $\lambda$
	\item Moltiplicare la riga $i$ per uno scalare $\lambda$
	\item Permutare fra loro due righe, diciamo $i$ e $j$
\end{enumerate}
A questo punto possiamo definire la forma a scalini per righe di una matrice.
In questo caso chiameremo \emph{profondità} di una riga la posizione occupata,
contata da destra, dal suo coefficiente diverso da zero che sta più a sinistra
nella riga. La riga nulla ha \emph{profondità} 0.

\begin{definition}
	Una matrice $A$ in $\Mat{m \times n}(\K)$, si dice \textbf{in forma
		a scalini per righe} se:
	\begin{itemize}
		\item Leggendo la matrice dall'alto verso il basso, le righe non nulle si
		      incontrano tutte prima delle righe nulle.
		\item Leggendo la matrice dall'alto verso il basso, le profondità
		      delle sue righe non nulle risultano strettamente decrescenti.
	\end{itemize}
\end{definition}

\begin{theorem}
	Data una matrice $A$ in $\Mat{m \times n}(\K)$ è sempre possibile,
	usando un numero finito di operazioni elementari sulle righe, ridurre la
	matrice in forma a scalini per righe.
\end{theorem}

In particolare, anche quando abbiamo una matrice in forma a scalini per righe, si
possono definire i \textbf{pivot} della matrice, come i coefficienti più a
sinistra delle righe non nulle.

Inoltre anche in questo caso è possibile definire una forma a scalini
\emph{particolare}: la forma a \textbf{scalini per righe ridotta}.

\begin{example}
	matrice in forma a scalini per righe
	\[
		\begin{pmatrix}
			1 & 0 & 0 & -20 \\
			0 & 1 & 0 & 0   \\
			0 & 0 & 1 & 5
		\end{pmatrix}
	\]
\end{example}

\begin{corollary}
	Ogni matrice $A$ può essere trasformata, attraverso le operazioni elementari
	sulle righe, in una matrice in forma a scalini per righe ridotta.
\end{corollary}

In generale valgono tutte le proprietà già elencate per le operazioni sulle
colonne.

\section{Riduzione a scalini e applicazioni lineari}

\begin{theorem}
	Data una applicazione lineare $L : V \to W$ tra due spazi vettoriali $V$ e
	$W$ sul campo $\K$, e data la matrice $[L]$ associata a $L$ rispetto
	a due basi fissate di $V$ e $W$:
	\begin{enumerate}
		\item Il massimo numero di righe linearmente indipendenti di $[L]$ è
		      uguale al massimo numero di colonne linearmente indipendenti di
		      $[L]$, ossia al rango di $L$.
		\item Se si riduce la matrice $[L]$ a scalini, sia che lo si faccia
		      per righe, sia che lo si faccia per colonne, il numero di scalini
		      sarà sempre uguale al rango di $L$.
	\end{enumerate}
\end{theorem}

\begin{observation}
	Se componiamo $L$ a destra o a sinistra per una	applicazione invertibile,
	il rango non cambia. Dunque, se moltiplichiamo $[L]$ a destra o a sinistra
	per matrici invertibili, anche il rango della matrice prodotto non cambia.
\end{observation}

\begin{proposition}
	Se $A$ è una matrice $m \times n$ a valori su un campo $\K$, ed
	indichiamo con $e_1, \dots, e_n$ le sue colonne, e $B$ è una riduzione
	a scalini per righe di $A$, allora le colonne di $A$ in corrispondenza alla
	posizione dei pivot di $B$ formano una base dello $Span$ delle colonne di $A$
	($Span(e_1, \dots, e_n)$).
\end{proposition}

\begin{observation}
	A partire dalla proposizione precedente possiamo ricavare un algoritmo per
	estrarre una base di uno spazio vettoriale da un insieme di generatori.

	Consideriamo $V$ uno spazio vettoriale di dimensione $n$ e del quale
	conosciamo una base $\{e_1, \dots, e_n\}$. Consideriamo $k$ vettori
	$v_1, \dots, v_k$ di $V$ e il sottospazio di $V$ generato da
	$Span(v_1, \dots, v_k)$. Se vogliamo estrarre una base di
	$Span(v_1, \dots, v_k)$ da $v_1, \dots, v_k$ seguiamo questi passaggi:
	\begin{enumerate}
		\item Scriviamo le coordinate dei $v_i$ rispetto alla base
		      $\{e_1, \dots, e_n\}$ e le	consideriamo come colonne di
		      una matrice $M$.
		\item Porto $M$ in forma a scalini per riga.
		\item I vari vettori $v_i$ con indice $i$ in corrispondenza dei pivot di $M'$
		      ($M$ in forma a scalini) formano una base di $Span(v_1, \dots, v_k)$,
		      estratta dall'insieme di generatori $\{v_1, \dots, v_k\}$.
	\end{enumerate}
\end{observation}