\chapter{Diagonalizzazione di endomorfismi lineari}
\section{Autovalori e autovettori}
Sia $T : V \to V$ un endomorfismo lineare dello spazio $V$ sul campo $\K$.

\begin{definition}
	Un vettore $v \in V - \{O\}$ si dice un \textbf{autovettore} di $T$ se
	\[
		T(v) = \lambda v
	\]
	per un certo $\lambda \in \K$.
\end{definition}

In altre parole un autovettore di $T$ è un vettore diverso da $O$ dello spazio $V$
che ha la seguente proprietà: la $T$ lo manda in un multiplo di se stesso.

\begin{definition}
	Se $v \in V - \{O\}$ è un autovettore di $T$ tale che
	\[
		T(v) = \lambda v
	\]
	allora lo scalare $\lambda \in \K$ si dice \textbf{autovalore} di $T$
	relativo a $v$ (e viceversa si dice che $v$ è un autovettore relativo a
	$\lambda$).
\end{definition}

Si noti che l'autovalore può essere $0 \in \K$: se per esempio $T$ non
è iniettiva, ossia $\Ker(T) \supsetneq \{O\}$, tutti gli elementi
$w \in (\Ker(T)) - \{O\}$ soddisfano
\[
	T(w) = O = 0w
\]
ossia sono autovettori relativi all'autovalore 0.

\begin{definition}
	Dato $\lambda \in \K$ chiamiamo l'insieme
	\[
		V_\lambda = \{v \in V \mid T(v) = \lambda v\}
	\]
	\textbf{autospazio} relativo a $\lambda$.
\end{definition}

\begin{observation}
	Possiamo notare dalla definizione precedente che $V_0 = \Ker(T)$.
\end{observation}

Anche se abbiamo definito l'autospazio $V_\lambda$ per qualunque
$\lambda \in \K$, in realtà $V_\lambda$ è sempre uguale a $\{O\}$ a
meno che $\lambda$ non sia un autovalore. Questo è dunque il caso interessante:
se $\lambda$ è un autovalore di $T$ allora $V_\lambda$ è costituito da $O$ e
da tutti gli autovettori relativi a $\lambda$.

Ma perché sono importanti autovettori e autovalori ?
Supponiamo che $V$ abbia dimensione $n$ e pensiamo a cosa succederebbe se
riuscissimo a trovare una base di $V$, $\{v_1, v_2, \dots, v_n\}$, composta solo
da autovettori di $T$.

Avremmo, per ogni $i = 1, 2, \dots, n$,
\[
	T(v_i) = \lambda_i v_i
\]
per certi autovalori $\lambda_i$.

Come sarebbe fatta la matrice
\[
	[T]_{\substack{
				v_1, v_2, \dots, v_n \\
				v_1, v_2, \dots, v_n
			}}
\]
associata a $T$ rispetto a questa base ?

Ricordandoci come si costruiscono le matrici osserviamo che la prima colonna
conterrebbe il vettore $T(v_1)$ scritto in termini della base $\{v_1, \dots v_n\}$,
ossia
\[
	T(v_1) = \lambda_1 v_1 + 0 v_2 + 0 v_3 + \cdots + 0 v_n
\]
la seconda il vettore $T(v_2) = 0 v_1 + \lambda_2 v_2 + 0 v_3 + \cdots + 0 v_n$ e
così via. Otterremo quindi una matrice diagonale.
\[
	[T]_{\substack{
				v_1, v_2, \dots, v_n \\
				v_1, v_2, \dots, v_n
			}} = \begin{pmatrix}
		\lambda_1 & 0         & 0     & 0         \\
		0         & \lambda_2 & 0     & 0         \\
		0         & 0         & \dots & 0         \\
		0         & 0         & 0     & \lambda_n
	\end{pmatrix}
\]

Da questa matrice possiamo ricavare a colpo d'occhio informazioni come
\begin{itemize}
	\item Il rango di $T$.
	\item La dimensione del nucleo.
	\item Quali sono i vettori di $\Ker(T)$.
	\item Quali sono (se esistono) i sottospazi in cui $T$ si comporta come l'identità,
	      ossia i sottospazi costituiti dai vettori di $V$ che $T$ lascia fissi.
\end{itemize}

Dunque l'obbiettivo di studiare autovalori e autovettori di $T$ è quello di
trovare basi "buone" che ci permettano di conoscere bene il comportamento di $T$.
Tuttavia non esistono sempre queste basi buone. E si dice che, se per un certo
endomorfismo $T$ esiste una base buona, questo è \textbf{diagonalizzabile}.

\begin{example}
	Consideriamo l'endomorfismo $R_{\theta} : \R^2 \to \R^2$ dato
	da una \emph{rotazione} di angolo $\theta$ con centro l'origine. Si verifica
	immediatamente che, rispetto alla base standard di $\R^2$, questo
	endomorfismo è rappresentato dalla matrice
	\[
		[R_\theta] = \begin{pmatrix}
			\cos{\theta} & -\sin{\theta} \\
			\sin{\theta} & \cos{\theta}
		\end{pmatrix}
	\]
	Per esempio nel caso di una rotazione di $60^\circ$ (ovvero $\frac{\pi}{3}$),
	abbiamo:
	\[
		R_{\frac{\pi}{3}} = \begin{pmatrix}
			\frac{1}{2}        & -\frac{\sqrt{3}}{2} \\
			\frac{\sqrt{3}}{2} & \frac{1}{2}
		\end{pmatrix}
	\]
	Nel caso in cui $0 < \theta < \pi$, non ci sono vettori $v \neq O$ che vengono
	mandati in un multiplo di se stessi, visto che tutti i vettori vengono ruotati
	di un angolo che non è nullo e non è di $180^\circ$. Dunque non ci sono
	autovalori e autovettori.

	Nel caso $\theta = 0$ la rotazione è l'identità, dunque tutti i vettori
	$v \neq O$ sono autovettori relativi all'autovalore 1, e $V_1 = \R^2$.

	Nel caso $\theta = \pi$ la rotazione è uguale a $-I$, dunque tutti i vettori
	$v \neq O$ sono autovettori relativi all'autovalore $-1$, e
	$V_{-1} = \R^2$.
\end{example}

\section{Polinomio caratteristico}
Vogliamo trovare dei criteri semplici per stabilire se un endomorfismo
è diagonalizzabile o no. Prima di tutto troviamo un metodo che, dato un
endomorfismo $T : V \to V$ e posto $n = \dim(V)$, ci permetta di decidere se
uno scalare $\lambda \in \K$ è o no un autovalore di $T$. Entrano
qui in gioco i polinomi e le loro radici.

Innanzitutto osserviamo che, perché $\lambda \in \K$ sia un
autovalore, secondo la definizione bisogna che esista un $v \in V - \{O\}$
tale che
\[
	T(v) = \lambda v
\]
Questo si può riscrivere anche come
\[
	T(v) - \lambda I(v) = O
\]
dove $I : V \to V$ è l'identità. Riscriviamo ancora:
\[
	(T - \lambda I)(v) = O
\]
Abbiamo scoperto che, se $T$ possiede un autovalore $\lambda$, allora
l'endomorfismo $T - \lambda I$ non è iniettivo: infatti manda il vettore
$v$ in $O$. Dunque, se scegliamo una base qualunque per $V$ e costruiamo la
matrice $[T]$ associata a $T$, la matrice $[T - \lambda I] = [T] - \lambda I$
dovrà avere determinante uguale a 0:
\[
	det([T] - \lambda I) = 0 = det(\lambda I - [T])
\]
dove come consuetudine abbiamo indicato con $I$ anche la matrice identità.

\begin{definition}
	Dato un endomorfismo $T : V \to V$ con $n = \dim(V)$, scegliamo una base
	per $V$ e costruiamo la matrice $[T]$ associata a $T$ rispetto a tale
	base. Il \textbf{polinomio caratteristico} $P_T(t) \in \K[t]$
	dell'endomorfismo $T$ è definito da:
	\[
		P_T(t) = det(t[I] - [T])
	\]
\end{definition}

\begin{observation}
	Prima di procedere dobbiamo fare un paio di considerazioni:
	\begin{enumerate}
		\item Perché la definizione precedente abbia senso si deve verificare
		      che \[det(t[I] - [T])\] sia veramente un polinomio. Questo si può
		      dimostrare facilmente per induzione sulla dimensione
		      $n$ di $V$.
		\item È fondamentale inoltre che la definizione appena data non dipenda
		      dalla base scelta di $V$: non sarebbe una definizione buona se con
		      la scelta di due basi diverse ottenessimo due polinomi
		      caratteristici diversi.
	\end{enumerate}
\end{observation}

Questo problema per fortuna non si verifica. Infatti se scegliamo due basi $b$ e
$b'$ di $V$, come sappiamo, le due matrici $[T]_{\substack{b \\ b}}$ e
$[T]_{\substack{b' \\ b'}}$ sono legate dalla seguente relazione: esiste una
matrice $[B]$ invertibile tale che
\[
	[T]_{\substack{b \\ b}} =
		[B]^{-1} [T]_{\substack{b' \\ b'}} [B]
\]

Usando il teorema di Binet a questo punto verifichiamo che
\begin{gather*}
	det \left(tI - [T]_{\substack{b \\ b}}\right) = \\
	det \left(tI - [B]^{-1} [T]_{\substack{b' \\ b'}} [B]\right) = \\
	det \left([B]^{-1} \left(tI - [T]_{\substack{b' \\ b'}}\right) [B] \right) = \\
	det \left([B]^{-1}\right) det \left(tI - [T]_{\substack{b' \\ b'}}\right)
	det \left([B]\right) = \\
	det \left(tI - [T]_{\substack{b' \\ b'}}\right)
\end{gather*}

Abbiamo dunque mostrato che $P_T(t) = det(tI - [T])$ non dipende dalla scelta della
base.

\begin{theorem}
	Considerato $T$ come sopra, vale che uno scalare $\lambda \in \K$ è un
	autovalore di $T$ se e solo se $\lambda$ è una radice di $P_T(t)$, ossia se e
	solo se $P_T(\lambda) = 0$.
\end{theorem}

\begin{example}
	Consideriamo l'endomorfismo $T : \mathbb{C}^2 \to \mathbb{C}^2$ che, rispetto
	alla base standard di $\mathbb{C}^2$, è rappresentato dalla matrice
	\[
		[T] = \begin{pmatrix}
			\frac{1}{2}        & -\frac{\sqrt{3}}{2} \\
			\frac{\sqrt{3}}{2} & \frac{1}{2}
		\end{pmatrix}
	\]
	Il suo polinomio caratteristico risulta $P_T(t) = t^2 - t + 1$. Questo polinomio
	ha due radici in $\mathbb{C}$, ovvero $\frac{1 - i\sqrt{3}}{2}$ e
	$\frac{1 + i\sqrt{3}}{2}$, che in effetti, come sappiamo, sono gli autovalori
	di $T$.
\end{example}


\section{Strategia per scoprire se un endomorfismo è diagonalizzabile}
Con il metodo descritto a breve si potrà scoprire se un endomorfismo
$T : V \to V$, dove $V$ è uno spazio vettoriale su $\K$ di dimensione $n$
è diagonalizzabile, e, in caso lo sia, si potrà trovare una base che lo diagonalizza,
ossia una base di $V$ fatta tutta di autovettori di $T$.

\begin{itemize}
	\item PASSO 1. Troviamo gli autovalori di un endomorfismo lineare $T$ calcolando il polinomio
	      caratteristico e le sue radici in $\K$.
	\item PASSO 2. Supponiamo dunque di aver trovato gli autovalori di $T$. A questo punto
	      vogliamo individuare gli autospazi relativi a tali autovalori.
	      Per questo basterà calcolare il $\Ker([T] - \lambda_i I)$. Prendiamo dunque la
	      matrice $[T] - \lambda_i I$ e risolviamo il sistema lineare omogeneo associato.
	\item PASSO 3. Per prima cosa enunciamo il seguente teorema
	      \begin{theorem}
		      Dato un endomorfismo $T : V \to V$, siano $\lambda_1, \dots, \lambda_k$
		      degli autovalori di $T$ distinti fra loro. Consideriamo ora degli autovettori
		      $v_1 \in V_{\lambda_1}, \dots, v_k \in V_{\lambda_k}$. Allora
		      $v_1, \dots, v_k$ è un insieme di vettori linearmente indipendenti.
	      \end{theorem}

	      Il seguente teorema è un rafforazamento del precedente.
	      \begin{theorem}
		      Dato un endomorfismo $T : V \to V$, siano $\lambda_1, \dots, \lambda_k$ degli
		      autovalori di $T$ distinti fra loro. Allora gli autospazi
		      $V_{\lambda_1}, \dots, V_{\lambda_k}$, sono in somma diretta.
	      \end{theorem}

	      Nelle ipotesi del teorema precedente sappiamo allora, che la dimensione della somma
	      degli autospazi è la massima possibile, ossia
	      \[
		      \dim(V_{\lambda_1} \oplus \cdots \oplus V_{\lambda_k}) = \dim(V_{\lambda_1}) +
		      \cdots + \dim(V_{\lambda_k})
	      \]

	      Osserviamo che abbiamo già un criterio per dire se $T$ è diagonalizzabile o no.
	      Ovvero, se
	      \[
		      \dim(V_{\lambda_1}) + \cdots + \dim(V_{\lambda_k}) = n = \dim(V)
	      \]
	      altrimenti se
	      \[
		      \dim(V_{\lambda_1}) + \cdots + \dim(V_{\lambda_k}) < n = \dim(V)
	      \]
	      $T$ non è diagonalizzabile. Infatti non è possibile trovare una base di
	      autovettori.
	\item PASSO 4. Se l'endomorfismo $T$ è diagonalizzabile, scegliamo allora una base di
	      autovettori nel modo descritto al Passo 3, e avremo una matrice associata $[T]$ che
	      risulterà diagonale. Mantenendo la notazione introdotta al Passo 3 troviamo sulla
	      diagonale $\dim(V_{\lambda_1})$ coefficienti uguali a
	      $\lambda_1$, ... e $\dim(V_{\lambda_k})$ coefficienti uguali a $\lambda_k$.
\end{itemize}
Il rango di $T$ sarà uguale al numero dei coefficienti non nulli che troviamo
sulla diagonale di $[T]$, la dimensione del nucleo sarà uguale al numero dei
coefficienti uguali a zero che troviamo sulla diagonale di $[T]$.

\begin{example}
	Consideriamo l'endomorfismo
	\[
		T \begin{pmatrix} x \\ y \end{pmatrix} =
		\begin{pmatrix}
			x + 2y \\
			-y
		\end{pmatrix}
	\]
	e la sua matrice associata rispetto alle basi standard
	\[
		[T] = \begin{pmatrix}
			1 & 2  \\
			0 & -1
		\end{pmatrix}
	\]
	Per prima cosa calcoliamo la matrice $[T] - tI$ che chiameremo $M$ per comodità
	\[
		M = \begin{pmatrix}
			t - 1 & -2    \\
			0     & t + 1
		\end{pmatrix}
	\]
	Troviamo il polinomio caratteristico calcolando il determinante di $M$ e otteniamo
	\[
		P_T(t) = (t - 1)(t + 1)
	\]
	Le radici di tale polinomio (e quindi gli autovalori di $T$) sono $t = 1$ e $t = -1$.
	Dobbiamo trovare quindi i relativi autospazi.
	\begin{itemize}
		\item Se $t = 1$ dobbiamo calcolare $\Ker([T] - 1I)$. Dobbiamo quindi risolvere il
		      sistema associato alla matrice
		      \[
			      \begin{pmatrix}
				      1 - 1 & -2    \\
				      0     & 1 + 1
			      \end{pmatrix} =
			      \begin{pmatrix}
				      0 & -2 \\
				      0 & 2
			      \end{pmatrix}
		      \]
		      ovvero
		      \[
			      \begin{cases}
				      -2y & = 0 \\
				      2y  & = 0
			      \end{cases} \quad \Rightarrow \quad
			      y = 0
		      \]
		      otteniamo dunque che l'autospazio $V_1$ è definito come segue
		      \[
			      V_1 = < \begin{pmatrix} 1 \\ 0 \end{pmatrix} > \quad \Rightarrow \quad
			      \dim(V_1) = 1
		      \]
		\item Se $t = -1$ procediamo in maniera analoga. Stavolta otteniamo il sistema
		      \[
			      \begin{cases}
				      -2x - 2y & = 0 \\
			      \end{cases} \quad \Rightarrow \quad
			      x = -y
		      \]
		      Ne deduciamo che l'autospazio $V_2$ sarà definito come segue
		      \[
			      V_2 = < \begin{pmatrix} -1 \\ 1 \end{pmatrix} > \quad \Rightarrow \quad
			      \dim(V_2) = 1
		      \]
	\end{itemize}
	Dato che $T$ è definta su $\R^2$ che ha dimensione 2 e dato che
	\[ \dim(V_1) + \dim(V_2) = 2 \] l'endomorfismo è diagonalizzabile.
\end{example}


\section{Strategia per scoprire se un endomorfismo è diagonalizzabile}
Con il metodo descritto a breve si potrà scoprire se un endomorfismo
$T : V \to V$, dove $V$ è uno spazio vettoriale su $\K$ di dimensione $n$
è diagonalizzabile, e, in caso lo sia, si potrà trovare una base che lo diagonalizza,
ossia una base di $V$ fatta tutta di autovettori di $T$.

\begin{itemize}
	\item PASSO 1. Troviamo gli autovalori di un endomorfismo lineare $T$ calcolando il polinomio
	      caratteristico e le sue radici in $\K$.
	\item PASSO 2. Supponiamo dunque di aver trovato gli autovalori di $T$. A questo punto
	      vogliamo individuare gli autospazi relativi a tali autovalori.
	      Per questo basterà calcolare il $\Ker([T] - \lambda_i I)$. Prendiamo dunque la
	      matrice $[T] - \lambda_i I$ e risolviamo il sistema lineare omogeneo associato.
	\item PASSO 3. Per prima cosa enunciamo il seguente teorema
	      \begin{theorem}
		      Dato un endomorfismo $T : V \to V$, siano $\lambda_1, \dots, \lambda_k$
		      degli autovalori di $T$ distinti fra loro. Consideriamo ora degli autovettori
		      $v_1 \in V_{\lambda_1}, \dots, v_k \in V_{\lambda_k}$. Allora
		      $v_1, \dots, v_k$ è un insieme di vettori linearmente indipendenti.
	      \end{theorem}

	      Il seguente teorema è un rafforazamento del precedente.
	      \begin{theorem}
		      Dato un endomorfismo $T : V \to V$, siano $\lambda_1, \dots, \lambda_k$ degli
		      autovalori di $T$ distinti fra loro. Allora gli autospazi
		      $V_{\lambda_1}, \dots, V_{\lambda_k}$, sono in somma diretta.
	      \end{theorem}

	      Nelle ipotesi del teorema precedente sappiamo allora, che la dimensione della somma
	      degli autospazi è la massima possibile, ossia
	      \[
		      \dim(V_{\lambda_1} \oplus \cdots \oplus V_{\lambda_k}) = \dim(V_{\lambda_1}) +
		      \cdots + \dim(V_{\lambda_k})
	      \]

	      Osserviamo che abbiamo già un criterio per dire se $T$ è diagonalizzabile o no.
	      Ovvero, se
	      \[
		      \dim(V_{\lambda_1}) + \cdots + \dim(V_{\lambda_k}) = n = \dim(V)
	      \]
	      altrimenti se
	      \[
		      \dim(V_{\lambda_1}) + \cdots + \dim(V_{\lambda_k}) < n = \dim(V)
	      \]
	      $T$ non è diagonalizzabile. Infatti non è possibile trovare una base di
	      autovettori.
	\item PASSO 4. Se l'endomorfismo $T$ è diagonalizzabile, scegliamo allora una base di
	      autovettori nel modo descritto al Passo 3, e avremo una matrice associata $[T]$ che
	      risulterà diagonale. Mantenendo la notazione introdotta al Passo 3 troviamo sulla
	      diagonale $\dim(V_{\lambda_1})$ coefficienti uguali a
	      $\lambda_1$, ... e $\dim(V_{\lambda_k})$ coefficienti uguali a $\lambda_k$.
\end{itemize}
Il rango di $T$ sarà uguale al numero dei coefficienti non nulli che troviamo
sulla diagonale di $[T]$, la dimensione del nucleo sarà uguale al numero dei
coefficienti uguali a zero che troviamo sulla diagonale di $[T]$.

\begin{example}
	Consideriamo l'endomorfismo
	\[
		T \begin{pmatrix} x \\ y \end{pmatrix} =
		\begin{pmatrix}
			x + 2y \\
			-y
		\end{pmatrix}
	\]
	e la sua matrice associata rispetto alle basi standard
	\[
		[T] = \begin{pmatrix}
			1 & 2  \\
			0 & -1
		\end{pmatrix}
	\]
	Per prima cosa calcoliamo la matrice $[T] - tI$ che chiameremo $M$ per comodità
	\[
		M = \begin{pmatrix}
			t - 1 & -2    \\
			0     & t + 1
		\end{pmatrix}
	\]
	Troviamo il polinomio caratteristico calcolando il determinante di $M$ e otteniamo
	\[
		P_T(t) = (t - 1)(t + 1)
	\]
	Le radici di tale polinomio (e quindi gli autovalori di $T$) sono $t = 1$ e $t = -1$.
	Dobbiamo trovare quindi i relativi autospazi.
	\begin{itemize}
		\item Se $t = 1$ dobbiamo calcolare $\Ker([T] - 1I)$. Dobbiamo quindi risolvere il
		      sistema associato alla matrice
		      \[
			      \begin{pmatrix}
				      1 - 1 & -2    \\
				      0     & 1 + 1
			      \end{pmatrix} =
			      \begin{pmatrix}
				      0 & -2 \\
				      0 & 2
			      \end{pmatrix}
		      \]
		      ovvero
		      \[
			      \begin{cases}
				      -2y & = 0 \\
				      2y  & = 0
			      \end{cases} \quad \Rightarrow \quad
			      y = 0
		      \]
		      otteniamo dunque che l'autospazio $V_1$ è definito come segue
		      \[
			      V_1 = < \begin{pmatrix} 1 \\ 0 \end{pmatrix} > \quad \Rightarrow \quad
			      \dim(V_1) = 1
		      \]
		\item Se $t = -1$ procediamo in maniera analoga. Stavolta otteniamo il sistema
		      \[
			      \begin{cases}
				      -2x - 2y & = 0 \\
			      \end{cases} \quad \Rightarrow \quad
			      x = -y
		      \]
		      Ne deduciamo che l'autospazio $V_2$ sarà definito come segue
		      \[
			      V_2 = < \begin{pmatrix} -1 \\ 1 \end{pmatrix} > \quad \Rightarrow \quad
			      \dim(V_2) = 1
		      \]
	\end{itemize}
	Dato che $T$ è definta su $\R^2$ che ha dimensione 2 e dato che
	\[ \dim(V_1) + \dim(V_2) = 2 \] l'endomorfismo è diagonalizzabile.
\end{example}