
% MATRICI E VETTORI

\subsection{Matrici e vettori}

\begin{defn}
	Dati due interi positivi $m, n$, una \textbf{matrice} $m \times n$
	a coefficienti in $\mathbb{K}$ \`e una griglia composta da $m$ righe
	e $n$ colonne in cui in ogni posizione c'\`e un elemento di
	$\mathbb{K}$:
	\begin{equation*}
		A = \begin{pmatrix}
			a_{11} & a_{12} & \dots & a_{1n} \\
			a_{21} & a_{22} & \dots & \dots  \\
			\dots  & \dots  & \dots & \dots  \\
			a_{m1} & \dots  & \dots & a_{mn}
		\end{pmatrix}
	\end{equation*}
	Per indicare l'elemento che si trova nella riga $i$-esima
	dall'alto e	nella colonna $j$-esima da sinistra viene indicato
	con $a_{ij}$. Spesso per indicare la matrice $A$ useremo la notazione
	$A = (a_{ij})$ e per ricordare le dimensioni della matrice scriveremo:
	\begin{equation*}
		A = (a_{ij})_{\substack{
					i = 1, 2, \dots, m \\
					j = 1, 2, \dots, n
				}}
	\end{equation*}
\end{defn}

\begin{defn}
	Dati due interi positivi m, n, chiamiamo
	$Mat_{m \times n} (\mathbb{K})$, l'insieme di tutte le matrici
	$m \times n$ a coefficienti in $\mathbb{K}$.
\end{defn}

\begin{defn}
	Sull'insieme $Mat_{m \times n} (\mathbb{K})$ possiamo definire la
	\textbf{somma} e il \textbf{prodotto per scalare}. Date due matrici
	$A, B \in Mat_{m \times n} (\mathbb{K})$ e dato uno scalare
	$k \in \mathbb{K}$, definiamo:
	\begin{itemize}
		\item
		      La \textbf{matrice somma} $A + B = C$, il cui generico coefficiente nella
		      $i$-esima riga e $j$-esima colonna si ottiene sommando i
		      coefficienti nella stessa posizione indicata da $(i, j)$ di $A$ e
		      di $B$. Ovvero per ogni $i \leq m$ e per ogni $j \leq n$
		      ho che $c_{ij} = a_{ij} + b_{ij}$.
		\item
		      La \textbf{matrice prodotto per scalare} $k \cdot A = D$, il cui
		      generico coefficiente nella $i$-esima riga e $j$-esima
		      colonna si ottiene moltiplicando lo scalare $k$ per il
		      coefficiente di $A$ in posizione $(i, j)$. Ovvero per ogni
		      $i \leq m$ e per ogni $j \leq n$ ho che
		      $d_{ij} = k \cdot a_{ij}$.
	\end{itemize}
\end{defn}

Esiste un'altra operazione, si tratta del
\emph{prodotto righe per colonne}. Per definire tale prodotto \`e
importante l'ordine in cui si considerano le due matrici (quindi non vale la
proprit\`a commutativa). Inoltre tale operazione \`e definita solo quando il
numero di colonne di $A$ \`e uguale al numero di righe di $B$.

\begin{defn}
	Data una matrice $A = (a_{ij}) \in Mat_{m \times n} (\mathbb{K})$ e una
	matrice $B = (b_{st}) \in Mat_{n \times k} (\mathbb{K})$, il
	\textbf{prodotto riga per colonna} $AB$, \`e la matrice
	$C = (c_{rh}) \in Mat_{m \times k} (\mathbb{K})$, i cui coefficienti,
	per ogni $r, h$, sono definiti come segue:
	\begin{equation*}
		c_{rh} = a_{r1} b_{1h} + a_{r2} b_{2h} + \cdots + a_{rn} b_{nh}
	\end{equation*}
\end{defn}

\begin{example}
	Consideriamo la matrice $A \in Mat_{2 \times 3}(\mathbb{K})$:
	\begin{equation*}
		A = \begin{pmatrix}
			1 & 2 & 4 \\
			0 & 6 & 3
		\end{pmatrix}
	\end{equation*}
	e la matrice $B \in Mat_{3 \times 3}(\mathbb{K})$:
	\begin{equation*}
		B = \begin{pmatrix}
			2 & 2 & 2  \\
			5 & 6 & -8 \\
			0 & 1 & 0
		\end{pmatrix}
	\end{equation*}
	La definizione ci dice che possiamo definire $C = AB$ e che $C$ \`e la matrice di
	$Mat_{2 \times 3}(\mathbb{K})$ i cui coefficienti sono ottenuti come segue:
	\begin{gather*}
		c_{11} = 1 \cdot 2 + 2 \cdot 5 + 4 \cdot 0 = 12 \\
		c_{12} = 1 \cdot 2 + 2 \cdot 6 + 4 \cdot 1 = 18 \\
		c_{13} = 1 \cdot 2 + 2 \cdot (-8) + 4 \cdot 0 = -14 \\
		c_{21} = 0 \cdot 2 + 6 \cdot 5 + 3 \cdot 0 = 30 \\
		c_{22} = 0 \cdot 2 + 6 \cdot 6 + 3 \cdot 1 = 39 \\
		c_{23} = 0 \cdot 2 + 6 \cdot (-8) + 3 \cdot 0 = -48
	\end{gather*}
	E dunque si ha:
	\begin{equation*}
		AB = C = \begin{pmatrix}
			12 & 18 & -14 \\
			30 & 39 & -48
		\end{pmatrix}
	\end{equation*}
\end{example}

\begin{defn}
	Data un'applicazione lineare $L$ da uno spazio vettoriale $V$ di
	dimensione $n$ ad uno spazio vettoriale $W$ di dimensione $m$, si dice
	\textbf{matrice associata} all'applicazione lineare $L$ nelle basi
	$\{e_1, e_2, \dots, e_n\}$ di $V$ e
	$\{\epsilon_1, \epsilon_2, \dots, \epsilon_m\}$ di $W$, la seguente
	matrice di $m$ righe ed $n$ colonne:
	\begin{equation*}
		[L]_{\substack{
				e_1, e_2, \dots, e_n\\
				\epsilon_1, \epsilon_2, \dots, \epsilon_m
			}} = \begin{pmatrix}
			a_{11} & a_{12} & \dots & a_{1n} \\
			a_{21} & a_{22} & \dots & \dots  \\
			\dots  & \dots  & \dots & \dots  \\
			a_{m1} & \dots  & \dots & a_{mn}
		\end{pmatrix}
	\end{equation*}
	dove $\{e_1, e_2, \dots, e_n\}$ \`e la base di partenza e
	$\{\epsilon_1, \epsilon_2, \dots, \epsilon_m\}$ \`e la base di arrivo.
\end{defn}

Sar\`a tutto pi\`u chiaro con un esempio che vedremo tra poco. In ogni caso, per
alleggerire la notazione, si possono omettere le basi, tuttavia si deve ricordare che
la matrice $[L]$ associata all'applicazione lineare $L$, non dipende solo da $L$ stessa,
ma anche dalle basi scelte per $V$ e $W$.

\begin{example}
	Consideriamo gli spazi vettoriali $\mathbb{R}^4$ con la sua base
	\begin{equation*}
		v_1 = \begin{pmatrix}
			1 \\ 1 \\ 0 \\ 0
		\end{pmatrix} \quad
		v_2 = \begin{pmatrix}
			0 \\ 1 \\ 1 \\ 0
		\end{pmatrix} \quad
		v_3 = \begin{pmatrix}
			0 \\ 0 \\ 1 \\ 1
		\end{pmatrix} \quad
		v_4 = \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 1
		\end{pmatrix}
	\end{equation*}
	e $\mathbb{R}^3$ con la sua base
	\begin{equation*}
		w_1 = \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} \quad
		w_2 = \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} \quad
		w_3 = \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}
	\end{equation*}
	Quel che vogliamo fare \`e scrivere la matrice associata all'applicazione lineare
	\begin{equation*}
		L \begin{pmatrix}
			x \\ y \\ z \\ w
		\end{pmatrix} = \begin{pmatrix}
			x + y + z \\
			y - z     \\
			x + w
		\end{pmatrix}
	\end{equation*}
	Procediamo calcolando l'immagine di ognuna delle componenti della base di
	$\mathbb{R}^4$
	\begin{gather*}
		L \begin{pmatrix}
			1 \\ 1 \\ 0 \\ 0
		\end{pmatrix} =
		\begin{pmatrix}
			2 \\ 1 \\ 1
		\end{pmatrix} \quad
		L \begin{pmatrix}
			0 \\ 1 \\ 1 \\ 0
		\end{pmatrix} =
		\begin{pmatrix}
			2 \\ 0 \\ 0
		\end{pmatrix} \\
		L \begin{pmatrix}
			0 \\ 0 \\ 1 \\ 1
		\end{pmatrix} =
		\begin{pmatrix}
			1 \\ -1 \\ 1
		\end{pmatrix} \quad
		L \begin{pmatrix}
			0 \\ 0 \\ 0 \\ 1
		\end{pmatrix} =
		\begin{pmatrix}
			0 \\ 0 \\ 1
		\end{pmatrix}
	\end{gather*}
	Ora dobbiamo esprimere i risultati trovati come combinazioni lineari della base di
	$\mathbb{R}^3$.
	\begin{gather*}
		\begin{pmatrix}
			2 \\ 1 \\ 1
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}\\
		\\
		\begin{pmatrix}
			2 \\ 0 \\ 0
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}\\
		\\
		\begin{pmatrix}
			1 \\ -1 \\ 1
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}\\
		\\
		\begin{pmatrix}
			0 \\ 0 \\ 1
		\end{pmatrix} =
		a \begin{pmatrix}
			1 \\ 0 \\ 1
		\end{pmatrix} +
		b \begin{pmatrix}
			1 \\ 1 \\ 1
		\end{pmatrix} +
		c \begin{pmatrix}
			0 \\ 0 \\ 2
		\end{pmatrix}
	\end{gather*}
	Ottengo dunque quattro sistemi.
	\begin{gather*}
		\begin{cases}
			a + b      & = 2 \\
			b          & = 1 \\
			a + b + 2c & = 1
		\end{cases}
		\quad
		\begin{cases}
			a + b      & = 2 \\
			b          & = 0 \\
			a + b + 2c & = 0
		\end{cases} \\
		\\
		\begin{cases}
			a + b      & = 1  \\
			b          & = -1 \\
			a + b + 2c & = 1
		\end{cases}
		\quad
		\begin{cases}
			a + b      & = 0 \\
			b          & = 0 \\
			a + b + 2c & = 2
		\end{cases}
	\end{gather*}
	Se li risolvo ottengo
	\begin{gather*}
		\begin{cases}
			a & = 1  \\
			b & = 1  \\
			c & = -1
		\end{cases}
		\quad
		\begin{cases}
			a & = 2  \\
			b & = 0  \\
			c & = -1
		\end{cases} \\
		\\
		\begin{cases}
			a & = 2  \\
			b & = -1 \\
			c & = 0
		\end{cases}
		\quad
		\begin{cases}
			a & = 0 \\
			b & = 0 \\
			c & = 1
		\end{cases}
	\end{gather*}
	Ora non devo fare altro che prendere i vettori
	\begin{equation*}
		\begin{pmatrix}
			1 \\ 1 \\ -1
		\end{pmatrix}
		\quad
		\begin{pmatrix}
			2 \\ 0 \\ -1
		\end{pmatrix}
		\quad
		\begin{pmatrix}
			2 \\ -1 \\ 0
		\end{pmatrix}
		\quad
		\begin{pmatrix}
			0 \\ 0 \\ -1
		\end{pmatrix}
	\end{equation*}
	e formare la matrice associata all'applicazione lineare $L$.
	\begin{equation*}
		[L]_{\substack{v_1, v_2, v_3, v_4 \\
				w_1, w_2, w_3}} =
		\begin{pmatrix}
			1  & 2  & 2  & 0  \\
			1  & 0  & -1 & 0  \\
			-1 & -1 & 0  & -1
		\end{pmatrix}
	\end{equation*}
\end{example}

\begin{observation}
	Dati due spazi vettoriali $V$ e $W$, esiste una sola applicazione
	lineare da $V$ a $W$ la cui matrice associata \`e indipendente dalle
	basi scelte. Questa \`e l'\emph{applicazione nulla}
	$\mathcal{O} : V \rightarrow W$ che manda ogni $v \in V$ in $O \in W$.
	Qualunque siano le basi scelte, la matrice associata avr\`a tutti
	i coefficienti uguali a $0$.
\end{observation}

\begin{observation}
	Consideriamo l'applicazione \emph{identit\`a} $I : V \rightarrow V$,
	che lascia fisso ogni elemento di $v: I(v) = v \forall v \in V$, e
	fissiamo la base $\mathcal{B}$ di $V$. Si verifica che la matrice
	$[I] = (a_{ij})$, associata ad $I$ rispetto a $\mathcal{B}$, sia in
	arrivo che in partenza, \`e la matrice quadrata di formato $n \times n$
	che ha tutti i coefficienti uguali a $0$ eccetto quelli sulla
	diagonale, che sono invece uguali a $1$.

	Tale matrice \`e l'elemento neutro rispetto alla moltiplicazione riga
	per colonna in $Mat_{n \times n}(\mathbb{K})$.

	In seguito useremo solo il simbolo $I$ per indicare sia la matrice identit\`a
	che	l'applicazione lineare $I$.
\end{observation}