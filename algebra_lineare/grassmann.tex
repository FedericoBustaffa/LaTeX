\chapter{La formula di Grassmann}
\section{La formula di Grassmann}

Dati due sottospazi vettoriali $A$ e $B$ in $\mathbb{R}^3$ di dimensione 2,
di che dimensione pu\`o essere la loro intersezione ?

Possono intersecarsi lungo una retta: in tal caso si nota che il sottospazio
generato dai vettori di $A \cup B$, ossia $A + B$, \`e tutto $\mathbb{R}^3$.

Oppure vale $A = B$: allora la loro intersezione \`e uguale ad $A$ (e a $B$) e
ha dimensione 2, e anche il sottospazio $A + B$ coincide con $A$.

In entrambi i casi, la somma delle dimensioni di $A \cap B$ e di $A + B$ \`e
sempre uguale a 4.

E se in $\mathbb{R}^4$ consideriamo un piano $C$ e un sottospazio $D$ di
dimensione 3?
Possono darsi tre casi per l'intersezione: $C \cap D = \{O\}$,
$dim(C \cap D) = 1$, $C \cap D = C$.

Qualunque sia il caso si verifica sempre che
\begin{equation*}
	dim(C \cap D) + dim(C + D) = 5 = dim(C) + dim(D)
\end{equation*}

In generale vale la formula
\begin{equation*}
	dim(A \cap B) + dim(A + B) = dim(A) + dim(B)
\end{equation*}

Dati due spazi vettoriali $V$ e $W$ sul campo $\mathbb{K}$, sul loro prodotto
cartesiano $V \times W$, c'\`e una struttura naturale di spazio vettoriale, dove
la somma \`e definita da:
\begin{equation*}
	(v, w) + (v_1, w_1) = (v + v_1, w + w_1)
\end{equation*}
e il prodotto per scalare da:
\begin{equation*}
	\lambda(v, w) = (\lambda v, \lambda w)
\end{equation*}
Si verifica che, se $\{v_1, \dots, v_n\}$ \`e una base di $V$
e $\{w_1, \dots, w_m\}$ \`e una base di $W$, allora
$\{(v_1, O), \dots (v_n, O), (O, w_1), \dots, (O, w_m)\}$ \`e una base di
$V \times W$, che dunque ha dimensione $n + m = (dim(V)) + (dim(W))$.

\begin{theorem}[Grassmann]
	Dati due sottospazi $A, B$ di uno spazio vettoriale $V$ sul campo
	$\mathbb{K}$, vale
	\begin{equation*}
		dim(A) + dim(B) = dim(A \cap B) + dim(A + B)
	\end{equation*}
	\begin{proof}
		Consideriamo l'applicazione
		\begin{equation*}
			\Phi : A \times B \to V
		\end{equation*}
		definita da
		\[ \Phi((a, b)) = a - b \]
		Cosa sappiamo dire del nucleo di $\Phi$ ? Per definizione
		\begin{equation*}
			Ker(\Phi) = \{(a, b) \in A \times B \mid a - b = O\}
		\end{equation*}
		dunque
		\begin{equation*}
			Ker(\Phi) = \{(a, b) \in A \times B \mid a = b\}
		\end{equation*}
		che equivale a scrivere:
		\begin{equation*}
			Ker(\Phi) = \{(z, z) \in A \times B \mid z \in A \cap B\}
		\end{equation*}
		Si nota subito che la applicazione lineare
		\[ \theta : A \cap B \to Ker(\Phi) \]
		\`e iniettiva e surgettiva, dunque \`e un isomorfismo. Allora il suo dominio e
		il suo codominio hanno la stessa dimensione, ovvero
		\begin{equation*}
			dim(Ker(\Phi)) = dim(A \cap B)
		\end{equation*}
		Cosa sappiamo dire invece dell'immagine di $\Phi$ ? Per definizione
		\begin{equation*}
			Imm(\Phi) = \{a - b \mid a \in A, b \in B\}
		\end{equation*}
		Visto che $B$, come ogni spazio vettoriale, se contiene un elemento
		$b$ contiene anche il suo opposto $-b$, possiamo scrivere la seguente
		uguaglianza fra insiemi:
		\begin{equation*}
			\{ a - b \mid a \in A, b \in B \} =
			\{ a + b \in V \mid a \in A, b \in B \} =
			A + B
		\end{equation*}
		Dunque
		\begin{equation*}
			Imm(\Phi) = A + B
		\end{equation*}
		Sappiamo che:
		\begin{equation*}
			dim(A \times B) = dim(Ker(\Phi)) + dim(Imm(\Phi))
		\end{equation*}
		Questa formula, viste le osservazioni fatte fin qui, si traduce come:
		\begin{equation*}
			dim(A) + dim(B) = dim(A \cap B) + dim(A + B)
		\end{equation*}
	\end{proof}
\end{theorem}

\section{Calcolo dell'intersezione di due sottospazi}
Consideriamo due sottospazi, $U$ e $W$, di $V$. Se entrambi sono presentati
come l'insieme delle soluzioni di un sistema \`e facile calcolare $U \cap W$:
basta calcolare le soluzioni del sistema 'doppio', ottenuto considerando tutte
le equazioni dei due sistemi.

Per esempio se $U$ e $W$ in $\mathbb{R}^4$ sono dati rispettivamente dalle
soluzioni dei sistemi $S_U$:
\begin{equation*}
	\begin{cases}
		3x + 2y + 4w = 0 \\
		2x + y + z + w = 0
	\end{cases}
\end{equation*}
e $S_W$:
\begin{equation*}
	\begin{cases}
		x + 2y + z + w = 0 \\
		x + z + w = 0
	\end{cases}
\end{equation*}
allora $U \cap W$ \`e dato dalle soluzioni del sistema:
\begin{equation*}
	\begin{cases}
		3x + 2y + 4w = 0   \\
		2x + y + z + w = 0 \\
		x + 2y + z + w = 0 \\
		x + z + w = 0
	\end{cases}
\end{equation*}

\begin{observation}
	Visto che $U$ ha dimensione 2, un sistema le cui soluzioni coincidono con
	l'insieme $U$ deve avere almeno 3 equazioni.
\end{observation}

Come calcolare per\`o $U \cap W$ se i due sottospazi sono presentati come span
di certi vettori ? Consideriamo per esempio $U$ e $W$ in $\mathbb{R}^5$
definiti cos\`i:
\begin{gather*}
	U = <\begin{pmatrix}
		1 \\ 2 \\ 3 \\ -1 \\ 2
	\end{pmatrix},
	\begin{pmatrix}
		2 \\ 4 \\ 7 \\ 2 \\ -1
	\end{pmatrix}> \\
	W = <\begin{pmatrix}
		1 \\ 2 \\ 0 \\ -2 \\ -1
	\end{pmatrix},
	\begin{pmatrix}
		0 \\ 1 \\ 1 \\ -1 \\ -1
	\end{pmatrix},
	\begin{pmatrix}
		0 \\ 1 \\ -3 \\ -6 \\ 1
	\end{pmatrix}>
\end{gather*}

Un metodo per calcolare $U \cap W$ \`e quello di esprimere $U$ e $W$ come
soluzioni di un sistema lineare. Cominciamo da $U$.

Per prima cosa si scrive la matrice:
\begin{equation*}
	\begin{pmatrix}
		1  & 2  & x_1 \\
		2  & 4  & x_2 \\
		3  & 7  & x_3 \\
		-1 & 2  & x_4 \\
		2  & -1 & x_5
	\end{pmatrix}
\end{equation*}
Ora riduciamo la matrice (senza incognite) a scalini per righe
\begin{equation*}
	\begin{pmatrix}
		1 & 2 & x_1                 \\
		0 & 1 & x_3 - 3x_1          \\
		0 & 0 & 2x_1 - x_2          \\
		0 & 0 & 13x_1 - 4x_3 + x_4  \\
		0 & 0 & -17x_1 + 5x_3 + x_5
	\end{pmatrix}
\end{equation*}
Tale matrice ha rango 2 se e solo se i coefficienti $x_1, x_2, x_3, x_4, x_5$ soddisfano
il sistema
\begin{equation*}
	\begin{cases}
		2x_1 - x_2          & = 0 \\
		13x_1 - 4x_3 + x_4  & = 0 \\
		-17x_1 + 5x_3 + x_5 & = 0
	\end{cases}
\end{equation*}

Ora dobbiamo fare la stessa cosa con $W$. Scriviamo quindi la matrice
\begin{equation*}
	\begin{pmatrix}
		1  & 0  & 0  & x_1 \\
		2  & 1  & 1  & x_2 \\
		0  & 1  & -3 & x_3 \\
		-2 & -1 & -6 & x_4 \\
		-1 & -1 & 1  & x_5
	\end{pmatrix}
\end{equation*}
e riduciamola a scalini per righe
\begin{equation*}
	\begin{pmatrix}
		1 & 0 & 0 & x_1                       \\
		0 & 1 & 1 & x_2 - 2x_1                \\
		0 & 0 & 2 & x_5 - x_1 + x_2           \\
		0 & 0 & 0 & x_3 + x_2 + 2x_5          \\
		0 & 0 & 0 & 2x_4 + 7x_2 + 5x_5 - 5x_1
	\end{pmatrix}
\end{equation*}
La matrice ha rango 3 se e solo se i coefficienti $x_1, x_2, x_3, x_4, x_5$ soddisfano il
sistema
\begin{equation*}
	\begin{cases}
		x_3 + x_2 + 2x_5          & = 0 \\
		2x_4 + 7x_2 + 5x_5 - 5x_1 & = 0 \\
	\end{cases}
\end{equation*}

Uniamo i due sistemi ottenuti e otteniamo
\begin{equation*}
	\begin{cases}
		2x_1 - x_2                & = 0 \\
		13x_1 - 4x_3 + x_4        & = 0 \\
		17x_1 - 5x_3 - x_5        & = 0 \\
		x_2 + x_3 + 2x_5          & = 0 \\
		5x_1 - 7x_2 - 2x_4 - 5x_5 & = 0
	\end{cases}
\end{equation*}
Se risolviamo questo sistema otteniamo una base di $U \cap W$. Per verificare che i calcoli
siano corretti basta vedere se la dimensione risulta uguale a quella prevista dalla formula
di Grassmann.

\section{Somma diretta di sottospazi}
Si dice che due sottospazi $U$ e $W$ di uno spazio vettoriale $V$ sono in
\textbf{somma diretta} se vale che \[ U \cap W = \{O\} \] In questo caso,
come sappiamo dalla formula di Grassmann, la dimensione di $U + W$ \`e "la
massima possibile", ovvero \[ dim(U) + dim(W) \] Vale anche il
viceversa, ossia due sottospazi sono in somma diretta se e solo se
\[ dim(U + W) = dim(U) + dim(W) \] Quando siamo sicuri che $U + W$ \`e la somma di due
sottospazi che sono in somma diretta, al posto di $U + W$ possiamo scrivere:
\begin{equation*}
	U \oplus W
\end{equation*}
In particolare, per avere una base di $U \oplus W$ basta fare l'unione di una
base di $U$ con una base di $W$.

\begin{observation}
	Attenzione: un sottospazio vettoriale $U$ di $V$ che non \`e uguale a $V$
	possiede in generale molti complementari. Per esempio, in $\mathbb{R}^3$
	un piano passante per l'origine ha per complementare una qualunque retta
	passante per l'origine e che non giace sul piano.
\end{observation}

In generale dati $k$ sottospazi $U_1, \dots, U_k$ di uno spazio vettoriale $V$,
si dice che tali sottospazi sono in somma diretta se, per ogni
$i = 1, \dots, k$, vale che l'intersezione di $U_i$ con la somma di tutti
gli altri \`e uguale a $\{O\}$, ovvero
\begin{equation*}
	U_i \cap (U_1 + \cdots + \hat{U_i} + \cdots + U_k) = \{O\}
\end{equation*}
dove il simbolo $\hat{U_i}$ indica che nella somma si \`e saltato il termine
$U_i$.

In tal caso per indicare $U_1 + \cdots + U_k$ si pu\`o usare la notazione:
\begin{equation*}
	U_1 \oplus \cdots \oplus U_k
\end{equation*}