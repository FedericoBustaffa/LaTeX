\chapter{Ricerca locale}
Nella ricerca classica, vista nei capitoli \ref{chapter: ricerca non informata}
e \ref{chapter: euristica}, l'agente risolutore assume che l'ambiente sia
completamente osservabile e deterministico e che si trovi nelle condizioni di
produrre un piano che pu\`o essere eseguito senza intoppi per raggiungere
l'obbiettivo.

\subsubsection{Ambienti pi\`u realistici}
La ricerca nell'intero spazio degli stati, che sia sistematica o con euristica,
\`e troppo costosa. Abbiamo bisogno di metodi di \textbf{ricerca locale} che siano
anche in grado di gestire ambienti parzialmente osservabili e azioni non
deterministiche.

\subsubsection{Algoritmi di ricerca locale}
Gli algoritmi visti fino ad ora esplorano gli spazi di ricerca alla ricerca di un
goal e restituiscono un \emph{cammino soluzione}. Ma a volte la soluzione del problema
coincide con lo stato goal. Gli algoritmi di ricerca locale sono adatti per problemi in
cui:
\begin{itemize}
	\item La sequenza di azioni non \`e importante: quello che conta \`e unicamente
	      lo stato goal.
	\item Tutti gli elementi della soluzione sono nello stato ma alcuni vincoli sono
	      violati.
\end{itemize}
Gli algoritmi di ricerca locale in generale:
\begin{itemize}
	\item Non sono sistematici.
	\item Tengono traccia solo del nodo corrente e si spostano sui nodi adiacenti.
	\item Non tengono traccia dei cammini, dunque
	      \begin{itemize}
		      \item Sono efficienti in memoria.
		      \item Possono trovare soluzioni ragionevoli anche in spazi molto grandi e
		            infiniti (come nel continuo).
	      \end{itemize}
	\item Sono utili per risolvere problemi di ottimizzazione, come trovare:
	      \begin{itemize}
		      \item Lo stato migliore secondo una funzione obbiettivo.
		      \item Lo stato di costo minore.
	      \end{itemize}
\end{itemize}

\section{Hill climbing}
\`E una ricerca locale di tipo greedy. Vengono generati i successori e valutati. Il successore
viene scelto se migliora lo stato attuale. Ci sono tre sottocategorie di questo algoritmo che
dipendono dalla modalit\`a di scelta del successore:
\begin{itemize}
	\item Se viene scelto il successore migliore abbiamo un \textbf{Hill climbing a salita rapida}.
	\item Se ne viene preso uno a caso tra quelli che migliorano lo stato abbiamo un
	      \textbf{Hill climbing stocastico}.
	\item Se viene scelto il primo successore che migliore lo stato abbiamo un
	      \textbf{Hill climbing con prima scelta}.
\end{itemize}
Se nessuno dei successori \`e migliore l'algoritmo fallisce.

\begin{lstlisting}[style=pseudo-style]
Hill_climbing(problema)
	nodo = problema.statoIniziale;
	while true
		successore = nodo.migliorSuccessore()
		if successore.valore <= nodo.valore then
			return nodo.valore;
		nodo = successore;
\end{lstlisting}

\subsubsection{Massimi e minimi locali}
Questo algoritmo ha per\`o a che fare con il problema dei \textbf{massimi e minimi locali}, ovvero
si potrebbe arrivare ad un punto in cui nessun successore migliora lo stato facendo cos\`i terminare
l'algoritmo senza arrivare all'ottimo, ovvero il \textbf{massimo o minimo globale} che potrebbe
trovarsi pi\`u avanti.

\subsubsection{Miglioramenti per Hill climbing}
\begin{itemize}
	\item Consentire un numero limitato di mosse \textbf{laterali}, ovvero si continua anche
	      a parit\`a di $h$
	\item Hill climbing stocastico: si sceglie a caso tra le mosse in salita (se il problema
	      \`e trovare un minimo) per provare a superare il minimo locale e riuscire a proseguire.
	\item Hill climbing con prima scelta.
	\item Hill climbing con riavvio casuale: si riparte da un punto passato. Se la probabilit\`a
	      di successo \`e $p$, saranno necessarie in media $1 / p$ ripartenze per trovare la soluzione.
	      \`E tendenzialmente completo ma se ci sono molti minimi/massimi locali si blocca spesso.
\end{itemize}
