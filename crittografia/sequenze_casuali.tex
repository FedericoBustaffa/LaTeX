\chapter{Sequenze casuali}
Introdurre le sequenze casuali ci permette di alimentare \textbf{algoritmi randomizzati} e sono inoltre molto utili
per \textbf{generare le chiavi} di cifratura e decifrazione nel modo migliore possibile.

Prendiamo due sequenze di esempio $h_1$ e $h_2$, entrambe lunghe 20 cifre
\[
	\begin{matrix}
		h_1 = 1 & 1 & 1 & 1 & 1 & \dots & 1 & \dots & 1 \\
		h_2 = 0 & 1 & 1 & 0 & 0 & \dots & 0 & \dots & 0
	\end{matrix}
\]
facciamo finta di aver ottenuto entrambe le sequenze lanciando 20 volte una moneta. La probabilit\`a di ottenere sia
$h_1$ che $h_2$ con questo metodo \`e di $\frac{1}{2}^{20}$.

Se dovessimo indicare quale delle due \`e quella \emph{casuale} sarebbe naturale indicare $h_2$. Ma definiamo formalmente
cosa sia la \emph{casualit\`a} ?

Il matematico russo Kolmogorov ha descritto il \textbf{significato algoritmico di casualit\`a} per una sequenza binaria.

\begin{definition}[Kolmogorov]
	Una sequenza \emph{binaria} $h$ \`e \textbf{casuale} se non ammette un algoritmo $A$, in grado di descrivere $h$, la
	cui rappresentazione binaria sia pi\`u corta di $h$. Quindi $h$ \`e casuale se
	\[ |h| \leq |A_h| \]
	ovvero possiamo affermare che una sequenza non \`e casuale se c'\`e un algoritmo \emph{semplice} che la descrive.
\end{definition}

\begin{example}
	Prendiamo ora come esempio una sequenza $h$ di $n$ 1. Abbiamo che
	\[ |h| = n \]
	e un algoritmo $A_h$ che la descrive
	\begin{lstlisting}
	for(int i = 0; i < n; i++)
		print(1);
	\end{lstlisting}
	La lunghezza della rappresentazione in binario di $A_h$ avr\`a lunghezza
	\[ |A_h| = \text{cost} + \theta(\log n) \]
	dato che per rappresentare $n$ in binario ho bisogno di $\log n$ bit. Abbiamo quindi descritto con $\log n$	bit
	una sequenza di $n$ bit.
\end{example}

\begin{example}
	Considerando invece una sequenza $h$ che ci appare casuale e non presenta evidenti regolarit\`a, l'algoritmo di
	rappresentazione deve contenerla interamente al suo interno e la restituisce in output.
	\begin{lstlisting}
	print(1001011110...1010...);
	\end{lstlisting}
	In questo caso la lunghezza della rappresentazione in binario di $A_h$ avr\`a lunghezza
	\[ |A_h| = \text{cost} + \theta(n) \]
	dato che non ho un modo compatto per descrivere $h$.
\end{example}

\section{Sistemi di calcolo}
Iniziamo ora a mettere in relazione le sequenze con i \textbf{sistemi di calcolo} dai quali vengono generate.

Prima di addentrarci nell'argomento facciamo qualche precisazione. I sistemi di calcolo sono certamente \emph{infiniti}
ma anche \emph{numerabili} dato che devo poterli descrivere con sequenze finite di caratteri di un alfabeto finito.

\begin{definition}[Complessit\`a di Kolmogorov]
	Sia $h$ una sequenza, $S_i$ un generico sistema di calcolo e $p$ un programma scritto nel formalismo richiesto dal
	sistema di calcolo $S_i$. Indico con
	\[ K_{S_i}(h) = \min\{ |p| \mid S_i(p) = h \} \]
	la \textbf{complessit\`a di Kolmogorov}, ossia la lunghezza del programma pi\`u breve in grado di generare la
	sequenza $h$ nel sistema $S_i$.
\end{definition}

\subsection{Sistema di calcolo universale}
Ci\`o che vogliamo fare \`e rendere la definizione di casualit\`a indipendente dal sistema di calcolo adottato.

Tra i sistemi di calcolo esiste almeno un sistema di calcolo \textbf{universale} $S_u$ in grado di simulare tutti gli
altri sistemi di calcolo.

Questo sistema di calcolo prende in input una coppia $q$, formata da un indice $i$ (l'indice del sistema di calcolo da
andare a simulare) e un programma $p$ da far girare sul sistema di calcolo $S_i$.
\[ S_u(q) =  S_u (\langle i, p \rangle) = S_i (p) = h \]
Se andiamo a valutare la lunghezza di $q$ in bit otteniamo che
\[ |q| = |i| + |p| = \theta (\log i) + |p| \]
dato che per rappresentare $i$ ho bisogno di $\log i$ bit. Notiamo anche che $|i|$ \`e un termine che dipende unicamente
dal sistema di calcolo e non dalla sequenza $h$.