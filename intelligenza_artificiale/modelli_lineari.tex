\chapter{Modelli lineari}
I modelli lineari sono molto utili per risolvere \textbf{problemi di regressione}, che, come abbiamo gi\`a anticipato
hanno una funzione obbiettivo che restituisce un valore target di tipo \textbf{numerico}.

Il nostro obbiettivo \`e quello di riuscire ad approssimare una funzione a valori reali e continui che potrebbe restituire
anche dati imprecisi o \textbf{rumorosi}. Un tipico esempio di coppia presente nel training set sar\`a del tipo:
\[ (x, f(x) + rumore) \]

\section{Regressione lineare univariata}
Per utilizzare modelli lineari dobbiamo fare riferimento ad un sottoinsieme della classe di problemi descritta sopra, ovvero
la \textbf{regressione lineare univariata}, in cui si considerano modelli composti da funzioni lineari, che hanno una sola
variabile $x$ in input e una sola variabile $y$ in output.

Per questa classe di problemi si assume un modello espresso come
\[ h(x) = w_1 x + w_0 + r \]
dove i $w_i$ sono coefficienti reali o parametri liberi detti \textbf{pesi} e $r$ sia il rumore ossia l'errore che
commettiamo nello stimare la funzione obbiettivo

\subsection{Struttura del problema}
Quello che vogliamo fare \`e un'operazione di \textbf{fitting}, ossia tracciare una retta che passi il pi\`u vicino
possibile ad ognuno dei dati presenti nel training set. Nello specifico, vogliamo costruire un algoritmo di apprendimento
che riesca a stimare la $y$ corrispondente ad altri valori $x$ ancora non osservati, trovando $w_1$ e $w_0$ e
\emph{minimizzando} l'errore o perdita di precisione.

\subsubsection{Errore}
Come valore d'errore considereremo il quadrato dell'errore effettivo, poich\'e l'errore effettivo potrebbe avere valori
negativi e positivi che si compensano una volta sommati, facendoci interpretare male i dati. In questo modo l'errore \`e
cumulativo.
\[ loss(h_w) = E(w) = \sum_{p=1}^l (y_p - h_w(x_p))^2 = \sum_{p=1}^l (y_p - (w_1 x_p + w_0))^2 \]
Quello appena calcolato \`e un valore che indica la differenza tra il valore target presente nel training set e
il risultato calcolato dall'ipotesi $h$ per certi valori di $w$.

\subsection{Metodo di risoluzione}
Il nostro obbiettivo come abbiamo gi\`a detto \`e quello di trovare un valore dei coefficienti $w$ che minimizzi la perdita
di precisione. In altre parole, per ogni elemento del training set che analizziamo, modifichiamo i coefficienti della retta,
translandola e/o cambiando la sua inclinazione.

Per fare questo abbiamo bisogno di uno strumento gi\`a introdotto in precedenza: il \textbf{gradiente}.

L'idea \`e molto semplice ma anche efficace. Dato che nel training set sono forniti i valori $x$ e $y$, i valori incogniti
sono $w_1$ e $w_0$. Per trovarli
\begin{enumerate}
	\item Calcoliamo la funzione $loss$ per tutti gli esempi presenti nel training set.
	\item Calcoliamo la derivata parziale della funzione rispetto a $w_1$ e $w_0$.
	\item Eguagliamo le derivate a 0.
	\item Risolto il sistema ottengo $w_1$ e $w_0$ tali che la distanza tra i dati e la retta sia minima per tutti i dati.
\end{enumerate}