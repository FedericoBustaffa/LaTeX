\chapter{Modelli lineari}
I modelli lineari sono molto utili per risolvere \textbf{problemi di regressione}, che, come abbiamo gi\`a anticipato
hanno una funzione obbiettivo che restituisce un valore target di tipo \textbf{numerico reale}.

Il nostro obbiettivo \`e quello di riuscire ad approssimare una funzione a valori reali e continui che potrebbe restituire
anche dati imprecisi o \textbf{rumorosi}. Un tipico esempio di coppia presente nel training set sar\`a del tipo:
\[ (x, f(x) + rumore) \]

\section{Regressione lineare univariata}
Per capire meglio i modelli lineari facciamo riferimento ad un sottoinsieme della classe di problemi descritta sopra, ovvero
la \textbf{regressione lineare univariata}, in cui si considerano modelli composti da funzioni lineari, che hanno una sola
variabile $x$ in input e una sola variabile $y$ in output.

Per questa classe di problemi si assume un modello espresso come
\[ h(x) = w_1 x + w_0 \]
dove i $w_i$ sono coefficienti reali o parametri liberi detti \textbf{pesi}.

\subsection{Struttura del problema}
Quello che vogliamo fare \`e un'operazione di \textbf{fitting}, ossia tracciare una retta che passi il pi\`u vicino
possibile ad ognuno dei punti presenti nel training set. Nello specifico, vogliamo costruire un algoritmo di apprendimento
che riesca a stimare la $y$ corrispondente ad altri valori $x$ ancora non osservati, trovando $w_1$ e $w_0$ e
\emph{minimizzando} l'errore o perdita di precisione.

\subsubsection{Funzione di errore}
Il valore dell'errore accumulato su dati del training set \`e definito dalla seguente funzione:
\[ loss(h_w) = E(w) = \sum_{p=1}^l (y_p - h_w(x_p))^2 = \sum_{p=1}^l (y_p - (w_1 x_p + w_0))^2 \]
dove $l$ \`e il numero di esempi presenti nel training set.

In pratica non si fa altro che misurare la differenza tra il valore target del training set e il valore che restituisce
una certa approssimazione $h$.

Il valore trovato viene elevato al quadrato per due motivi:
\begin{enumerate}
	\item L'idea \`e che la funzione $E$ sommi tutti gli errori sui singoli dati ma il valore potrebbe essere sia positivo
	      che negativo e questo potrebbe portare ad un'errata diminuzione dell'errore o addirittura ad un annullamento.
	      Per evitare questo eleviamo l'errore al quadrato in modo da avere sempre un valore positivo.
	\item Una volta letto il punto precedente ci si potrebbe chidere perch\'e non usare il valore assoluto. Il motivo \`e
	      che vogliamo trovare il minimo della funzione $E$ e per farlo occorre calcolarne la derivata. La derivata di un
	      polinomio elevato al quadrato \`e semplicemente pi\`u comoda e pi\`u semplice da calcolare rispetto a quella
	      di un valore assoluto.
\end{enumerate}

\subsection{Metodo di risoluzione analitico - LMS}
La tecnica che vedremo \`e chiamata \emph{Least Mean Square} il cui obbiettivo \`e quello di trovare un valore dei
coefficienti $w$ che minimizzi l'errore quadratico.

Per fare questo abbiamo bisogno di uno strumento gi\`a introdotto in precedenza: il \textbf{gradiente}.

L'idea \`e molto semplice ma anche efficace. Dato che nel training set sono forniti i valori $x$ e $y$, i valori incogniti
sono $w_1$ e $w_0$. Per trovarli
\begin{enumerate}
	\item Calcoliamo la funzione $E$ per tutti gli esempi presenti nel training set.
	\item Calcoliamo la derivata parziale della funzione rispetto a $w_0$ e $w_1$, ossia calcoliamo il gradiente.
	\item Eguagliamo il gradiente a 0.
	      \[
		      \begin{pmatrix}
			      \displaystyle\frac{ \partial E(w) }{ \partial w_0 }, &
			      \displaystyle\frac{ \partial E(w) }{ \partial w_1 }
		      \end{pmatrix} = 0
	      \]
	\item Risolto il sistema ottengo $w_1$ e $w_0$ tali che la distanza tra i dati e la retta sia minima per tutti i dati.
\end{enumerate}

Agendo in maniera analitica abbiamo semplicemente trovato il punto stazionario corrispondente al minimo globale della
funzione $E$.

Adesso abbiamo una funzione $h_w$ con dei $w$ fissati con cui posso provare a calcolare nuovi $y$ relativi a nuovi
input $x$ non presenti nel training set.

Chiariamo che i nuovi valori $h_w(x)$ calcolati saranno approssimazioni del reale valore relativo a $x$, tranne rari casi
in cui il reale valore $y$ relativo a $x$ si trovi esattamente sulla retta trovata.

\subsection{Metodo algoritmico}
Adesso vogliamo per\`o vogliamo agire in maniera algoritmica e cerca la funzione giusta con un metodo simile a quello
visto nel capitolo \ref{chapter: ricerca_locale} quando parlavamo di ricerca locale in spazi continui.

Avevamo definito una regola che ci permetteva di muoverci in spazi continui seguendo le indicazioni del gradiente in questo
modo:
\[ x_{\text{new}} = x - \eta \nabla f(x) \]
Adesso dobbiamo semplicemente riadattarla come segue:
\[ w_{\text{new}} = w - \eta \nabla E(w) \]
Sapendo che
\[ -\nabla E(w) = \Delta w \]
posso riscrivere la funzione in questo modo:
\[ w_{\text{new}} = w + \eta \Delta w \]
Ricordiamo che $\eta$ rappresenta la dimensione del passo ($0 < \eta < 1$). Nell'ambito del machine learning rappresenta il cosidetto
\textbf{learning rate}.

Ora possiamo correggere la nostra stima man mano che assumiamo dati in questo modo:
\begin{itemize}
	\item Se $y = h(x)$ l'errore \`e nullo quindi non faccio niente.
	\item Se $h(x) > y$ posso compiere due operazioni:
	      \begin{itemize}
		      \item Traslo la retta in basso decrementando $w_0$: caso $\Delta w_0 < 0$.
		      \item Se $x > 0$ ruoto la retta decrementando $w_1$: caso $\Delta w_1 < 0$.
		      \item Altrimenti ruoto la retta incrementando $w_1$: caso $\Delta w_1 > 0$.
	      \end{itemize}
	\item Se $h(x) < y$ mi muovo in maniera speculare al punto precedente.
\end{itemize}

\subsubsection{Metodo di risoluzione online}
Prima definito quella che viene chiamata \textbf{politica batch} dell'algoritmo. In sostanza si prendono tutti i membri
presenti nel training set (\textbf{epoca}), si calcola la funzione $E$ finch\'e non si esauriscono ed infine si calcola
il gradiente per aggiornare i $w$.

Esiste anche un'altro modo di procedere. In pratica, quello che succede \`e che si calcola la funzione $E$ per un singolo
membro del training set e subito si aggiornano i $w$. Si ripete il procedimento per tutti i membri del training set.

Questo metodo fa subire al gradiente variazioni pi\`u imprevedibili e significative. Potrebbe essere pi\`u veloce ma
necessita di un $\eta$ pi\`u piccolo.
