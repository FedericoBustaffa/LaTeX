\chapter{Modelli lineari}
I modelli lineari sono molto utili per risolvere \textbf{problemi di regressione}, che, come abbiamo gi\`a anticipato
hanno una funzione obbiettivo che restituisce un valore target di tipo \textbf{numerico reale}.

Il nostro obbiettivo \`e quello di riuscire ad approssimare una funzione a valori reali e continui che potrebbe restituire
anche dati imprecisi o \textbf{rumorosi}. Un tipico esempio di coppia presente nel training set sar\`a del tipo:
\[ (x, f(x) + rumore) \]

\section{Regressione lineare univariata}
Per capire meglio i modelli lineari facciamo riferimento ad un sottoinsieme della classe di problemi descritta sopra, ovvero
la \textbf{regressione lineare univariata}, in cui si considerano modelli composti da funzioni lineari, che hanno una sola
variabile $x$ in input e una sola variabile $y$ in output.

Per questa classe di problemi si assume un modello espresso come
\[ h(x) = w_1 x + w_0 \]
dove i $w_i$ sono coefficienti reali o parametri liberi detti \textbf{pesi}.

\subsection{Struttura del problema}
Quello che vogliamo fare \`e un'operazione di \textbf{fitting}, ossia tracciare una retta che passi il pi\`u vicino
possibile ad ognuno dei punti presenti nel training set. Nello specifico, vogliamo costruire un algoritmo di apprendimento
che riesca a stimare la $y$ corrispondente ad altri valori $x$ ancora non osservati, trovando $w_1$ e $w_0$ e
\emph{minimizzando} l'errore o perdita di precisione.

\subsubsection{Funzione di errore}
Il valore dell'errore accumulato su dati del training set \`e definito dalla seguente funzione:
\[ loss(h_w) = E(w) = \sum_{p=1}^l (y_p - h_w(x_p))^2 = \sum_{p=1}^l (y_p - (w_1 x_p + w_0))^2 \]
dove $l$ \`e il numero di esempi presenti nel training set.

In pratica non si fa altro che misurare la differenza tra il valore target del training set e il valore che restituisce
una certa approssimazione $h$.

Il valore trovato viene elevato al quadrato per due motivi:
\begin{enumerate}
	\item L'idea \`e che la funzione $E$ sommi tutti gli errori sui singoli dati ma il valore potrebbe essere sia positivo
	      che negativo e questo potrebbe portare ad un'errata diminuzione dell'errore o addirittura ad un annullamento.
	      Per evitare questo eleviamo l'errore al quadrato in modo da avere sempre un valore positivo.
	\item Una volta letto il punto precedente ci si potrebbe chidere perch\'e non usare il valore assoluto. Il motivo \`e
	      che vogliamo trovare il minimo della funzione $E$ e per farlo occorre calcolarne la derivata. La derivata di un
	      polinomio elevato al quadrato \`e semplicemente pi\`u comoda e pi\`u semplice da calcolare rispetto a quella
	      di un valore assoluto.
\end{enumerate}

\subsection{Metodo di risoluzione analitico - LMS}
La tecnica che vedremo \`e chiamata \emph{Least Mean Square} il cui obbiettivo \`e quello di trovare un valore dei
coefficienti $w$ che minimizzi l'errore quadratico.

Per fare questo abbiamo bisogno di uno strumento gi\`a introdotto in precedenza: il \textbf{gradiente}.

L'idea \`e molto semplice ma anche efficace. Dato che nel training set sono forniti i valori $x$ e $y$, i valori incogniti
sono $w_1$ e $w_0$. Per trovarli
\begin{enumerate}
	\item Calcoliamo la funzione $E$ per tutti gli esempi presenti nel training set.
	\item Calcoliamo la derivata parziale della funzione rispetto a $w_0$ e $w_1$, ossia calcoliamo il gradiente.
	\item Eguagliamo il gradiente a 0.
	      \[
		      \begin{pmatrix}
			      \displaystyle\frac{ \partial E(w) }{ \partial w_0 }, &
			      \displaystyle\frac{ \partial E(w) }{ \partial w_1 }
		      \end{pmatrix} = 0
	      \]
	\item Risolto il sistema ottengo $w_1$ e $w_0$ tali che la distanza tra i dati e la retta sia minima per tutti i dati.
\end{enumerate}

Agendo in maniera analitica abbiamo semplicemente trovato il punto stazionario corrispondente al minimo globale della
funzione $E$.

Adesso abbiamo una funzione $h_w$ con dei $w$ fissati con cui posso provare a calcolare nuovi $y$ relativi a nuovi
input $x$ non presenti nel training set.

Chiariamo che i nuovi valori $h_w(x)$ calcolati saranno approssimazioni del reale valore relativo a $x$, tranne rari casi
in cui il reale valore $y$ relativo a $x$ si trovi esattamente sulla retta trovata.

\subsection{Metodo algoritmico}
Adesso vogliamo per\`o vogliamo agire in maniera algoritmica e cerca la funzione giusta con un metodo simile a quello
visto nel capitolo \ref{chapter: ricerca_locale} quando parlavamo di ricerca locale in spazi continui.

Avevamo definito una regola che ci permetteva di muoverci in spazi continui seguendo le indicazioni del gradiente in questo
modo:
\[ x_{\text{new}} = x \pm \eta \nabla f(x) \]
Adesso dobbiamo semplicemente riadattarla come segue:
\[ w_{\text{new}} = w - \eta \nabla E(w) \]
Sapendo che
\[ -\nabla E(w) = \Delta w \]
possiamo definire adesso la \textbf{regola delta} riscrivendo la funzione in questo modo:
\[ w_{\text{new}} = w + \eta \Delta w \]
Notiamo che nella ricerca locale usavamo $+\nabla f(x)$ per cercare massimi locali e $-\nabla f(x)$ per cercare minimi
locali. In questo caso siamo interessati solo ai minimi locali dunque nella formula comparir\`a sempre
$-\nabla E(w) = +\Delta w$.

Ricordiamo inoltre che $\eta$ rappresenta la dimensione del passo ($0 < \eta < 1$), che, in ambito Machine Learning,
rappresenta il \textbf{learning rate}.

Su questa base possiamo costruire un algoritmo di ricerca nello spazio delle ipotesi che corregge l'errore man mano che
si elaborano nuovi esempi del training set. Nello specifico le correzioni avvengono in questo modo:
\begin{itemize}
	\item Se $y = h(x)$ l'errore \`e nullo quindi non faccio niente.
	\item Se $h(x) > y$ significa che il valore atteso si trova sopra la nostra retta. Le correzioni che possiamo fare
	      sono quindi:
	      \begin{itemize}
		      \item Trasliamo la retta in basso decrementando $w_0$: caso $\Delta w_0 < 0$.
		      \item Se $x > 0$ ruotiamo la retta in senso orario decrementando $w_1$: caso $\Delta w_1 < 0$.
		      \item Altrimenti se $x < 0$ ruotiamo la retta in senso antiorario incrementando $w_1$: caso $\Delta w_1 > 0$.
	      \end{itemize}
	\item Se $h(x) < y$ mi muovo in maniera speculare al punto precedente.
\end{itemize}
Per velocizzare un po' i calcoli possiamo subito derivare le formule generali in questo modo
\begin{gather*}
	\Delta w_0 = -\frac{\partial E(w)}{\partial w_0} = 2 \cdot \sum_{p=1}^l (y_p - h_w(x)) \\
	\\
	\Delta w_1 = -\frac{\partial E(w)}{\partial w_1} = 2 \cdot \sum_{p=1}^l (y_p - h_w(x)) \cdot x_p
\end{gather*}

\subsubsection{Algoritmo}
Ora possiamo definire l'algoritmo come segue
\begin{enumerate}
	\item Iniziamo con dei valori di $w$ iniziali presi a caso e possibilmente piccoli.
	\item Fissiamo $\eta$ tra 0 e 1.
	\item \label{enum: delta w} Calcoliamo $\Delta w$ per ogni $w_i$.
	\item Calcoliamo $w_\text{new}$ per ogni $w_i$.
	\item Torniamo al punto \ref{enum: delta w} finch\'e non si ha una convergenza (non si migliora pi\`u) o
	      $E(w)$ non \`e abbastanza piccolo.
\end{enumerate}

L'algoritmo pu\`o essere implementato con due politiche differenti:
\begin{itemize}
	\item \textbf{Batch}: si calcola il $\Delta w$ su tutto l'insieme dei dati di training (\textbf{epoca}) in un solo
	      colpo svolgendo interamente la sommatoria. Solo alla fine si andr\`a ad applicare la regola delta per aggiornare
	      i pesi.

	      Questo approccio garantisce maggiore precisione e linearit\`a nel raggiungere la soluzione.
	\item \textbf{Online}: in questo caso non si svolge la sommatoria ma si calcola il $\Delta w$ per ogni esempio nel
	      training set e si va subito ad applicare la regola delta aggiornando i pesi ogni volta.

	      Questa politica pu\`o rendere l'algoritmo pi\`u veloce ma, generalmente, lo rende anche pi\`u instabile. necessita
	      quindi di un \textbf{learning rate} pi\`u basso rispetto alla politica batch.
\end{itemize}

\section{Input multidimensionale}
Abbiamo visto il caso base con una sola variabile in input ma nella realt\`a i problemi affrontati possono avere in input
molte variabili. Dobbiamo quindi trovare una regola pi\`u generale che ci aiuti a trattare problemi con pi\`u variabili in
input.

D'ora in avanti considereremo membri del training set (\textbf{pattern}) multidimensionali che hanno per l'appunto pi\`u
variabili di input e un valore target di output. Indicheremo quindi con $x_{p, i}$ l'$i$-esima variabile del $p$-esimo
pattern e $X$ sar\`a una matrice $l \times n$ dove $l$ \`e il numero di pattern e $n$ \`e il numero di variabili per ogni
pattern.

Stavolta la funzione da approssimare sar\`a nella forma
\[ h(x_1, \dots, x_n) = w_0 + w_1 x_1 + \dots + w_n x_n = w_0 + \sum_{i=1}^n w_i x_i \]
e non rappresenter\`a pi\`u una retta come nella regressione linerare univariata ma rappresenter\`a degli
\textbf{iperpiani}.

Per rendere pi\`u compatta la notazione useremo $x^T = [1, x_1, \dots, x_n]$ per indicare l'insieme delle $n$ variabili
in input relative a un generico pattern e $w = [w_0, w_1, \dots, w_n]$ per indicare i pesi. Ora possiamo riscrivere la
formula in maniera pi\`u compatta in questo modo:
\[ x^T w = \sum_{i=0}^n w_i x_i \]
Adesso possiamo facilmente definire la funzione $E$ per input multidimensionali come segue:
\[ E(w) = \sum_{p=1}^l (y_p - x^T_p w)^2 = \| y - X w \|^2 \]
Di conseguenza possiamo definire anche $\Delta w$ in questo modo:
\[
	\Delta w_i = -\frac{\partial E(w)}{\partial w_i} = 2 \sum_{p=1}^l (y_p - h_w(x_p)) \cdot x_{p, i} =
	\sum_{p=1}^l (y_p - x^T_p w) \cdot x_{p, i}
\]
Una volta definita l'equazione per input multidimensionale possiamo riutilizzare l'algoritmo visto in precedenza per la
regressione lineare univariata.

Possiamo inoltre costruire un algoritmo che non tiene un learning rate fisso ma lo decrementa col passare del tempo.
Questo fa s\`i che all'inizio la correzione dell'errore sia pi\`u grossolana evitandoci di procedere troppo lentamente,
in seguito per\`o, col decrescere dell'errore, anche le correzioni che dovremo fare saranno sempre pi\`u piccole. Un
learning rate pi\`u basso ci aiuta dunque ad essere pi\`u precisi man mano che ci si avvicina alla soluzione.

\section{Limitazioni}
Un grosso limite dei modelli lineari \`e il problema dell'\textbf{underfitting}. Questo si traduce in una scarsa
capacit\`a di approssimazione della funzione obbiettivo. Nel caso della regressione lineare univariata ad esempio posso
tracciare la miglior retta possibile ma potrei avere comunque un errore molto alto alcuni esempi di training.

Per la trattazione di problemi pi\`u complessi \`e necessario muoverci verso modelli \textbf{non lineari}, che vedremo nel
prossimo capitolo.