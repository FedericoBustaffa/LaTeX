\chapter{Relazioni non lineari}
Per approssimare meglio casi di regressione \`e molto conveniente passare a relazioni di tipo \textbf{non lineare}.
Fino ad ora abbiamo trattato modelli lineari espressi dalla formula
\[ h_w(x) = \sum_{i = 0}^n w_i x_i \]
con le variabili e coefficienti di grado 1. Adesso vogliamo passare a modelli pi\`u flessibili con una maggior
capacit\`a di approssimazione. Per farlo possiamo passare ad un polinomio di questo tipo
\[ h_w(x) = \sum_{i = 0}^n w_i x^i \]
Quella appena scritta \`e detta \textbf{regressione polinomiale} ma il modello resta lineare. Questo perch\'e ci\`o che
rende lineare un modello \`e la linearit\`a nei pesi $w$ e non nelle variabili $x$.

Precisiamo anche che la formula appena scritta vale solo per \textbf{regressioni polinomiali univariate}. Infatti se
notiamo, la variabile in ingresso \`e una sola ma ha grado $n$.

Questo \`e molto comodo e possiamo usare ancora l'algoritmo LMS per trovare una buona approssimazione della funzione
dato che il modello rimane lineare.

\section{Espansione lineare della base}
Quel che vogliamo fare ora \`e trovare modelli lineari ancora pi\`u flessibili e funzionanti per pi\`u variabili in
ingresso. Ecco che viene introdotta l'\textbf{espansione lineare di base}, la cui formula, ancora pi\`u generale della
precedente  \`e definita in questo modo:
\[ h_w(x) = \sum_{k = 0}^K w_k \phi_k(x) \]
dove $x$ equivale al pattern $x = [x_1, x_2, \dots, x_n]$ e dove $\phi$ \`e una funzione da
$\mathbb{R}^n$ in $\mathbb{R}$

Il modello appena rappresentato continua ad essere linerare nei coefficienti $w$ e anche in $\phi$ ma non lo \`e pi\`u
in $x$. Come gi\`a spiegato in precedenza, questo fa s\`i che il modello sia ancora lineare, consentendoci cos\`i di
utilizzare ancora l'algoritmo LMS per riuscire a trovare una buona approssimazione.

Quello che abbiamo introdotto ora ci consente un maggior grado di libert\`a nell'approssimazione della funzione ma ha
di contro il fatto che il modello potrebbe diventare \textbf{troppo complesso}. Dove per \emph{complessit\`a} intendiamo
il grado di libert\`a del modello. Un modello \`e tanto pi\`u espressivo, quanto pi\`u \`e complesso.

\section{Complessit\`a dei modelli}
Ora che abbiamo piena libert\`a di espressione per definire modelli flessibili a piacere, andiamo in contro a nuovi
problemi. Uno di questi \`e il problema della scelta per la $\phi$. La scelta di $\phi$ \`e fondamentale per costruire
un buon modello e in base a questa scelta andiamo incontro ad altri due problemi: l'\textbf{underfitting} e
l'\textbf{overfitting}.

Il primo esprime la scarsa capacit\`a di approssimazione del modello, il quale ammette molto rumore sui dati di test.

Il secondo, invece, denota una capacit\`a di approssimazione del modello altissima sui dati di test. Talmente alta da
non ammettere rumore su di essi o quasi. Ma per riuscire ad essere perfetto sui dati di test crea una funzione che
non riesce ad approssimare in maniera consistente la funzione obbiettivo.

