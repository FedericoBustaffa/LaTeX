\part{Machine Learning}
\chapter{Introduzione}
Il \textbf{Machine Learning} \`e un'area che combina l'esigenza di creare macchine in grado di apprendere con i nuovi
strumenti adattivi e statistici che di continuo vengono migliorati o inventati.

Il Machine Learning nasce dalla necessit\`a che abbiamo di analizzare una crescente quantit\`a di dati empirici combinata
con la difficolt\`a che si ha nel \emph{"programmare l'intelligenza"} a priori. L'unica scelta possibile \`e creare
macchine in grado di apprendere ed evolversi in modo da rendersi adattive in maniera autonoma e dunque senza avere bisogno
di essere programmate per risolvere problemi troppo specifici.

Tra i principali obbiettivi abbiamo:
\begin{itemize}
	\item \textbf{Intelligenza artificiale}: costruire \textbf{sistemi intelligenti adattivi}.
	\item \textbf{Apprendimento statistico}: costruire \textbf{sistemi di analisi dati} predittivi e computazionalmente
	      efficaci.
	\item \textbf{Innovazione in varie aree}: costruire \textbf{modelli} come strumento per problemi interdisciplinari
	      complessi.
\end{itemize}
In generale si cerca di creare modelli in grado di evolversi con una conoscenza a priori molto limitata ma sufficiente
da permettere al modello di imparare e ampliare tale conoscenza.

Il Machine Learning \`e in generale molto utile quando
\begin{itemize}
	\item La conoscenza o la teoria che sta dietro certi fenomeni \`e poca o in alcuni casi assente.
	\item C'\`e incertezza nei dati che possono essere incompleti o difficilmente decifrabili.
	\item Si trattano ambienti dinamici, ovvero non conosciuti a priori.
\end{itemize}

Ci sono tutta via dei requisiti perch\`e il processo sia svolto in maniera efficace:
\begin{itemize}
	\item Ci deve essere una fonte di apprendimento in modo da avere abbastanza dati per riuscire a costruire un
	      meccanismo che dia risultanti soddisfacenti.
	\item I dati in ingresso non possono essere troppo incompleti o troppo pochi. Dobbiamo avere una base solida da
	      cui iniziare.
\end{itemize}

Possiamo affermare a questo punto che ci sia bisogno di un nuovo paradigma computazionale differente da quello di
programmazione standard, in grado di trattare dati incerti e imprecisi. Tipicamente si parla di \textbf{soft computing} o
\textbf{intelligenza computazionale}.

L'obbiettivo \`e trovare soluzioni approssimative per problemi difficili da formalizzare scrivendo a mano un algoritmo.
Chiariamo che non si tratta di una metodologia approssimata, ma di un approccio rigoroso con forti basi
matematiche in grado di trovare funzioni/metodi di approssimazione a problemi complessi.

\section{Sistemi predittivi}
In generale si crea un modello che prende dei dati in input e in base a questi dati, esso muta e si evolve per poter
fare una \textbf{predizione} pi\`u accurata. Il processo di miglioramento del modello \`e guidato dal \textbf{compito}
che deve svolgere l'agente, dall'\textbf{algoritmo di apprendimento} e da un processo di \textbf{validazione} del modello.

\section{Apprendimento supervisionato}
Nell'\textbf{apprendimento supervisionato} abbiamo un vettore di valori in input (\textbf{training set}) che, attraverso
un \textbf{supervisore}, vengono associati a priori a valori o categorie.

Dunque avremo una coppia di input-output del tipo
\[ (x, d) \]
dove $x$ \`e un elemento del training set e $d$ \`e il \textbf{valore target} assegnatogli dal supervisore.
Il supervisore possiede a priori la conoscenza necessaria per associare ogni $x$ al relativo $d$, esiste tuttavia una
\textbf{funzione obbiettivo} $c$ che riesce a fare lo stesso
\[ c(x) = d \]
e che per\`o ci \`e sconosciuta.

L'obbiettivo dell'apprendimento \`e quello di trovare una \emph{buona} approssimazione di $c$, ossia un'\textbf{ipotesi}
$h$, tale che le relazioni decise a priori dal supervisore continuino ad essere vere e tale che sia anche in grado di
trovarne di nuove quanto pi\`u simili a quelle che troverebbe la funzione $c$ per nuovi dati in input.

La tipologia del valore target $d$ pu\`o essere
\begin{itemize}
	\item \textbf{Categorica}: problema di \textbf{classificazione} in cui $c(x)$ ritorna quella che \`e la classe
	      (assunta) corretta per $x$. In questo caso abbiamo che $c(x)$ \`e un funzione a valori discreti da 1 a $k$.
	\item \textbf{Numerica}: problema di \textbf{regressione}. In questo caso invece approssimiamo la funzione con
	      valori reali continui in $\mathbb{R}$ o $\mathbb{R}^k$.
\end{itemize}

\section{Apprendimento non supervisionato}
In questo caso ci vengono dati una serie di dati iniziali in input ma non abbiamo un \textbf{supervisore} che etichetta
a priori il valore target di questi dati.

In questo caso si cerca di trovare direttamente una relazione tra i dati presenti nel training set. In particolare si
cercano dati con valori simili tra loro e si prova ad approssimare una funzione che passi il pi\`u vicino possibile ad
ognuno di essi.

\subsection{Modelli}
Un \textbf{modello} vuole descrivere le relazioni tra i dati in base al compito da svolgere. Definisce inoltre la classe
di funzioni che possono essere implementate chiamato \emph{spazio delle ipotesi}, ovvero un insieme di funzioni
che pu\`o essere del tipo
\[ h(x, w) \]
dove $w$ \`e un parametro che pu\`o indicare l'errore o altri fattori che dipendono dal problema.

\section{Algoritmi di apprendimento}
Ricapitolando, i concetti di base per iniziare a parlare di algoritmi di apprendimento sono:
\begin{itemize}
	\item \textbf{Training set}: si tratta di un vettore di dati in input (\textbf{esempi}) con relativo valore target di
	      output che pu\`o anche essere inaccurato o impreciso.
	\item \textbf{Funzione obbiettivo}: L'effettiva funzione $c$ che stiamo stimando.
	\item \textbf{Ipotesi}: Un'approssimazione della funzione $c$ che descrive le relazioni tra i dati in input.
	\item \textbf{Spazio delle ipotesi}: L'insieme $H$ di tutte le possibili ipotesi $h$ che potrebbero in qualche modo
	      essere derivate dall'algoritmo.
\end{itemize}

Gli \textbf{algoritmi di apprendimento} di fatto vanno a trattare il problema di trovare la miglior $h$ come un problema
di ricerca (con euristica) nello spazio delle ipotesi. Tipicamente si cerca l'ipotesi che \emph{minimizza} l'errore.

Lo spazio delle ipotesi $H$ potrebbe non coincidere con l'insieme di tutte le possibili funzioni e la ricerca potrebbe
non essere esaustiva. Dobbiamo riuscire a fare assunzioni in grado di ridurre lo spazio di ricerca. Vedremo pi\`u avanti
i \textbf{bias induttivi}.

\subsection{Generalizzazione}
Come gi\`a detto in precedenza, l'apprendimento si basa sul trovare una funzione abbastanza \emph{buona} in uno spazio di
funzioni. Nello specifico si tratta di trovare una funzione che abbia una buona capacit\`a di \textbf{generalizzazione}.

L'\textbf{errore di generalizzazione} \`e un valore che misura quanto accuratamente, il modello, stima nuovi valori di
output per valori di input non presento nel training set. Tenendo di conto dell'errore e/o della perdita di informazione
durante il processo.

Per concludere possiamo dividere il processo complessivo in due fasi:
\begin{itemize}
	\item \textbf{Fase di apprendimento}: si basa sul costruire il modello in base ai dati e ai bias.
	\item \textbf{Fase predittiva}: \`e la fase in cui applichiamo il risultato dell'apprendimento ad un nuovo campione di
	      dati mai analizzati prima.
\end{itemize}
