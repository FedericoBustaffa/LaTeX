\section{Teoremi limite}
I \textbf{teoremi limite} entrano in gioco quando si vuole, in un certo senso, passare al lato
più empirico della statistica, ecco che vengono introdotti la \textbf{legge dei grandi numeri} e
il \textbf{teorema del limite centrale}.

Prendiamo per esempio il lancio di una moneta equilibrata. Se si effettuano 1000 lanci ci
aspettiamo di ottenere all'incirca 500 teste se la moneta è equilibrata. La legge dei grandi numeri
cerca di formalizzare questo risultato, mentre il teorema del limite centrale cerca di quantificare
le oscillazioni del numero di teste attorno a 500. Iniziamo però a dare qualche definizione.

\begin{definition}
	Data una famiglia di variabili aleatorie $X_1, X_2, \dots, X_n$ (possibilmente infinita), le
	variabili $X_i$ si dicono indipendenti e identicamente distribuite (i.i.d) se sono indipendenti
	e hanno la stessa distribuzione (cioè $P_{X_i}$ non dipende da $i$).

	Nel caso di famiglia infinita, diciamo che le $X_i$ sono indipendenti se $\forall n \in \N$ le
	variabili $X_1, X_2, \dots, X_n$ sono indipendenti.
\end{definition}

Dire che la variabile $X_i$ sono i.i.d equivale a dire che le $X_i$ hanno la stessa funzione di
ripartizione
\[ P(X_i \leq t) = F_{X_i} (t) = F(t) \]
per ogni $i$ e inoltre significa che sono indipendenti
\[ P(X_1 \leq t_1, \dots, X_n \leq t_n) = F_{X_1} (t_1) \cdot ... \cdot F_{X_n} (t_n) \]
per ogni $t_1, \dots, t_n \in \R$. Il tipico esempio di variabili aleatorie i.i.d è dato dalle
ripetizioni di un esperimento (non perforza con esisto successo o insuccesso).

Consideriamo $n$ (o anche infinite) ripetizioni di un esperimento nelle stesse condizioni. Sia
$X$ la variabile aleatoria che descrive un carattere dell'esperimento (ad esempio l'esito del
lancio di un dado). Per $i \in \N^+$, sia $X_i$ il valore del carattere dell'esito dell'$i$-esimo
esperimento. Allora le $X_i$ sono i.i.d.

Come caso particolare consideriamo l'estrazione di un campione da una popolazione reale.
Consideriamo quindi una popolazione e sia $X$ la variabile aleatoria che rappresenta un carattere
degli individui. Supponiamo ora di estrarre casualmente $n$ individui, in modo indipendente l'uno
dall'altro, e chiamiamo $X_i$ il carattere dell'$i$-esimo individuo estratto. Allora gli $X_i$
sono i.i.d con la stessa distribuzione di $X$.

Introduciamo ora la notazione per la media aritmetica di $n$ variabili aleatorie $X_1, \dots, X_n$
i.i.d
\[ \overline{X} = \overline{X_n} = \frac{X_1 + X_2 + \dots + X_n}{n} \]
Osserviamo che $\overline{X}$ è essa stessa una variabile aleatoria in quanto combinazione di
variabili aleatorie. Osserviamo anche che se $X_1, \dots, X_n$ rappresenta un campione,
$\overline{X}$ è la media campionaria del campione.

\begin{example}
	Consideriamo il caso di $n$ ripetizioni di un esperimento con esito successo o insuccesso.
	Chiamiamo $A$ il successo e sia $p = P(A)$ e sia $X_i$ la variabile aleatoria di Bernoulli
	associata all'$i$-esima ripetizione
	\[
		X_i = \begin{cases}
			1 & \text{se accade $A$ all'$i$-esima ripetizione} \\
			0 & \text{altrimenti}
		\end{cases}
	\]
	Allora le $X_i$ sono i.i.d indipendenti e con distribuzione $B(p)$, quindi $X=X_1+\dots+X_n$ è
	una variabile aleatoria $B(n,p)$ e rappresenta la \textbf{frequenza assoluta} del successo
	(di $A$) mentre
	\[ \overline{X} = \frac{X}{n} \]
	rappresenta la frequenza relativa del successo.
\end{example}

\subsection{Legge dei grandi numeri}
Uno degli obbiettivi fondamentali della legge dei grandi numeri è studiare il valore di
$\overline{X}$ per campioni grandi ($n$ grande). Questo significa calcolare in qualche modo il
limite, ma trattandosi di variabili aleatorie dobbiamo definire meglio cosa si intenda per limite.
Per la legge dei grandi numeri, ci serve la \textbf{convergenza in probabilità}.

\begin{definition}
	Una successione $Y_1, \dots, Y_n, \dots$ di variabili aleatorie definite sullo stesso spazio
	diciamo che \textbf{converge in probabilità} a una variabile aleatoria $Y$ se
	\[ P(|Y_n - Y| > \varepsilon) \to 0 \]
	per ogni $\varepsilon > 0$. In alternativa possiamo vedere la cosa in questo modo
	\[ \lim_{n \to +\infty} P(|Y_n - Y| > \varepsilon) = 0 \]
	Stiamo quindi dicendo che per $n$ grande $Y_n$ è vicina a $Y$ con probabilità alta.
\end{definition}

\begin{theorem}[Legge debole dei grandi numeri]
	Sia $X_1, \dots, X_n, \dots$ una successione di variabili aleatorie i.i.d dotate di momento
	secondo e sia $\mu = \E[X_i]$, allora $\overline{X}$ converge in probabilità a $\mu$, cioè
	\[ P(|\overline{X} - \mu| > \varepsilon) \to 0 \]
	per $n \to +\infty$ e per ogni $\varepsilon > 0$.
\end{theorem}

In altre parole il teorema dice che la media campionaria dei primi $n$ termini tende, per $n$
grande, al valore atteso. Valore atteso che è la media sulla popolazione nel caso di estrazione.
