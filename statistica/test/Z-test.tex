\section{Z-test}
Si vuole ora effettuare un test sulla media di una popolazione Gaussiana con varianza nota.
Definiamo quindi $X \sim N(\mu, \sigma^2)$ con $\sigma^2$ nota e sia $X_1, \dots, X_n$ un campione
i.i.d. di $X$. Come per l'intervallo di fiducia usiamo il fatto che
\[ \sqrt{n} \cdot \frac{\overline{X_n} - \mu}{\sigma} = Z \sim N(0,1) \]
Occupiamoci per il momento del test bilatero scrivendo le ipotesi
\[ H_0: \mu = \mu_0 \quad H_1: \mu \neq \mu_0 \]

\subsection{Formulazione del test}
Poiché $\overline{X_n}$ è la stima della media $\mu$,
l'intuizione ci porta a rifiutare l'ipotesi $H_0$ se $\overline{X_n}$ si discosta molto dal valore
$\mu_0$. Scegliamo quindi una regione critica
\[ C = \{ | \overline{X_n} - \mu_0 | > d \} \]
con $d$ da determinare. Per scegliere $d$ imponiamo che
\[ P_{\mu_0} (C) \leq \alpha \]
con $\alpha$ livello del test e per avere massima potenza del test imponiamo
\[ P_{\mu_0} (C) = \alpha \]
Questo vuol dire che
\begin{align*}
	\alpha = & P_{\mu_0} ( | \overline{X_n} - \mu_0 | > d )                   \\
	=        & P_{\mu_0} \left( \frac{\sqrt{n}}{\sigma} \cdot
	|\overline{X_n} - \mu_0| > \frac{\sqrt{n}}{\sigma} \cdot d \right)        \\
	=        & P_{\mu_0} \left( |Z| > \frac{\sqrt{n}}{\sigma} \cdot d \right)
\end{align*}
dove $Z$ è una Gaussiana standard. Continuando il calcolo abbiamo
\begin{align*}
	P_{\mu_0} \left( |Z| > \frac{\sqrt{n}}{\sigma} \cdot d \right)
	= & P_{\mu_0} \left( -\frac{\sqrt{n}}{\sigma} \cdot d < Z
	< \frac{\sqrt{n}}{\sigma} \cdot d \right)                           \\
	= & \Phi \left( \frac{\sqrt{n}}{\sigma} \cdot d \right) -
	\Phi \left( -\frac{\sqrt{n}}{\sigma} \cdot d \right)                \\
	= & 2 \cdot \Phi \left( \frac{\sqrt{n}}{\sigma} \cdot d \right) - 1
\end{align*}
A questo punto abbiamo che
\begin{gather*}
	\alpha = 2 \cdot \Phi \left( \frac{\sqrt{n}}{\sigma} \cdot d \right) - 1 \\
	\Leftrightarrow \\
	\Phi \left( \frac{\sqrt{n}}{\sigma} \cdot d \right) = 1 - \frac{\alpha}{2} \\
	\Leftrightarrow \\
	\frac{\sqrt{n}}{\sigma} \cdot d = q_{1 - \frac{\alpha}{2}} \\
	\Leftrightarrow \\
	d = \frac{\sigma}{\sqrt{n}} \cdot q_{1 - \frac{\alpha}{2}}
\end{gather*}
Otteniamo quindi la regione critica
\[
	C = \left\{ \sqrt{n} \cdot \frac{|\overline{X_n} -
		\mu_0|}{\sigma} > q_{1 - \frac{\alpha}{2}} \right\}
\]
In pratica, di fronte alla realizzazione $x_1, \dots, x_n$ del campione si calcola la media
empirica $\overline{x}$ e si rifiuta $H_0$ se e solo se
\[ \sqrt{n} \cdot \frac{|\overline{x_n} - \mu_0|}{\sigma} > q_{1 - \frac{\alpha}{2}}  \]
Notiamo che l'ampiezza della regione di accettazione $C^c$ che è
\[ 2 \cdot \frac{\sigma}{\sqrt{n}} \cdot q_{1 - \frac{\alpha}{2}} \]
\begin{itemize}
	\item Cresce al decrescere di $\alpha$
	\item Cresce al crescere di $\sigma^2$
	\item Decresce al crescere di $n$
\end{itemize}

\begin{observation}
	L'ipotesi $H_0: \mu = \mu_0$ è accettata al livello $\alpha$ se e solo se $\mu_0$ appartiene
	all'intervallo di fiducia di livello $1-\alpha$. Questa è una proprietà generale: si può
	dimostrare che è equivalente verificare un intervallo di fiducia di livello $1-\alpha$ e
	formulare un test di livello $\alpha$ con $H_0$ ipotesi semplice, cioè ridotta ad un unico
	valore del parametro ($H_0 : \theta = \theta_0$).
\end{observation}

\subsection{Calcolo del p-value}
Informalmente, il $p$-value dei dati $(x_1, \dots, x_n)$ è la probabilità, sotto $H_0$, di
ottenere dati più estremi, rispetto ad $H_0$, di $(x_1, \dots, x_n)$. Poiché $\overline{X_n}$ è
lo stimatore di $\mu$ e $H_0: \mu = \mu_0$, è intuitivo considerare, come dati più estremi, i dati
$(y_1, \dots, y_n)$ che verificano
\[ |\overline{y} - \mu_0| > |\overline{x} - \mu_0| \]
ci aspettiamo quindi che $\overline{y}$ sia più distante da $\mu_0$ rispetto a $\overline{x}$. Ci
aspettiamo quindi come $p$-value
\[
	\overline{\alpha} (x_1, \dots, x_n) =
	P_{\mu_0} (|\overline{X} - \mu_0| > |\overline{x} - \mu_0|)
\]
Per svolgere il calcolo usiamo la standardizzazione e otteniamo
\begin{align*}
	P_{\mu_0} (|\overline{X} - \mu_0| > |\overline{x} - \mu_0|)
	= & P_{\mu_0} \left( \frac{\sqrt{n}}{\sigma} \cdot |\overline{X} - \mu_0| >
	\frac{\sqrt{n}}{\sigma} \cdot |\overline{x} - \mu_0| \right)                    \\
	= & P \left( |Z| > \frac{\sqrt{n}}{\sigma} \cdot |\overline{x} - \mu_0| \right) \\
	= & 2 \cdot \left(1 - \Phi \left(\frac{\sqrt{n}}{\sigma} \cdot
		|\overline{x} - \mu_0| \right) \right)
\end{align*}
Si verifica che $\overline{\alpha}$ soddisfa la definizione rigorosa di $p$-value: si rifiuta $H_0$
se e solo se $\alpha > \overline{\alpha}$.

\subsection{Calcolo della curva operativa}
Come abbiamo detto, la curva operativa è
\begin{align*}
	\beta (\mu) = & P_\mu (C^c)                                                              \\
	=             & P_\mu \left( \sqrt{n} \cdot \frac{|\overline{X} - \mu_0|}{\sigma}
	\leq q_{1 - \frac{\alpha}{2}} \right)                                                    \\
	=             & P_\mu \left( -q_{1-\frac{\alpha}{2}} \leq
	\sqrt{n} \cdot \frac{\overline{X} - \mu_0}{\sigma} \leq q_{1 - \frac{\alpha}{2}} \right) \\
	=             & P_\mu \left( -q_{1-\frac{\alpha}{2}} \leq
	\sqrt{n} \cdot \frac{\overline{X} - \mu}{\sigma} + \sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma}
	\leq q_{1-\frac{\alpha}{2}} \right)                                                      \\
	=             & P_\mu \left( \sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma} -
	q_{1 - \frac{\alpha}{2}} \leq Z \leq
	\sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma} + q_{1-\frac{\alpha}{2}} \right)               \\
	=             & \Phi \left( \sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma} +
	q_{1-\frac{\alpha}{2}} \right) - \Phi \left( \sqrt{n} \cdot
	\frac{\mu - \mu_0}{\sigma} - q_{1-\frac{\alpha}{2}} \right)                              \\
	=             & h \left( \sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma} \right)
\end{align*}
Si può dimostrare che la funzione $h$ è pari e decrescente in $x \geq 0$ (ad $\alpha$ fissato).
Quindi più $\sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma}$ è grande, più la curva operativa è piccola
e quindi più grande è la potenza $1 - \beta(\mu)$.

Ne segue che, per aumentare la potenza $1 - \beta(\mu)$ (lasciando $\alpha$ fissato), si può
aumentare la taglia $n$ del campione. Più precisamente possiamo formalizzare la cosa in questo modo
\begin{align*}
	\beta (\mu) = & \Phi \left( \sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma} +
	q_{1-\frac{\alpha}{2}} \right) - \Phi \left( \sqrt{n} \cdot
	\frac{\mu - \mu_0}{\sigma} - q_{1-\frac{\alpha}{2}} \right)                 \\
	\leq          & 1 - \Phi \left( \sqrt{n} \cdot \frac{\mu - \mu_0}{\sigma} -
	q_{1-\frac{\alpha}{2}} \right)
\end{align*}
Se vogliamo che $1-\beta(\mu) \geq 1 - \beta_0$, imponiamo
\[
	1 - \Phi \left( \sqrt{n} \cdot \frac{|\mu_0 - \mu|}{\sigma} -
	q_{1-\frac{\alpha}{2}} \right) \leq \beta_0
\]

\subsection{Z-test unilatero}
Ragionamento molto simile al caso bilatero, infatti consideriamo $X \sim N(\mu, \sigma^2)$ con
$\sigma^2$ nota e $X_1, \dots, X_n$ un campione i.i.d. di $X$. In questo caso il test è però
unilatero e quindi abbiamo che
\[ H_0: \mu \leq \mu_0 \quad H_1: \mu > \mu_0 \]

\subsubsection{Formulazione del test}
L'intuizione ci spinge a rifiutare $H_0$ se $\overline{X} - \mu_0$ è grande, cioè a considerare
una regione critica della forma
\[ C = \{ \overline{X} - \mu_0 > d \} \]
La condizione sul livello $\alpha$ diventa
\[ P_\mu \{ \overline{X} - \mu_0 > d \} \leq \alpha \]
per ogni $\mu \leq \mu_0$. Si può dimostrare che la probabilità scritta sopra cresce al crescere
di $\mu$ e quindi basta imporre
\[ P_{\mu_0} (\overline{X} - \mu_0 > d) = \alpha \]
Facciamo ora uso della standardizzazione e otteniamo
\[
	P_{\mu_0} (\overline{X} - \mu_0 > d) =
	P_{\mu_0} \left( \frac{\sqrt{n}}{\sigma} \cdot (\overline{X} - \mu_0) >
	\frac{\sqrt{n}}{\sigma} \cdot d \right) = \alpha
\]
da cui $\frac{\sqrt{n}}{\sigma} \cdot d = q_{1-\alpha}$. Quindi
\[
	C = \left\{ \frac{\sqrt{n}}{\sigma} (\overline{X} - \mu_0) > q_{1-\alpha} \right\}
	= \left\{ \overline{X} - \mu_0 > \frac{\sigma}{\sqrt{n}} \cdot q_{1-\alpha} \right\}
\]
La dipendenza dell'ampiezza della regione di accettazione $C^c$ dai parametri $\alpha$, $\sigma$
ed $n$ è la stessa del caso bilatero.

\subsubsection{Calcolo del p-value}
I dati $(y_1, \dots, y_n)$ sono più estremi di $(x_1, \dots, x_n)$, rispetto ad
$H_0: \mu \leq \mu_0$, se $\overline{y} - \mu_0 > \overline{x} - \mu_0$. Quindi il $p$-value,
ossia la probabilità, sotto $H_0$ di avere dati più estremi di $(x_1, \dots, x_n)$ è
\[ P_\mu \left( \overline{X} - \mu_0 > \overline{x} - \mu_0 \right) \]
Come $p$-value si prende quindi il massimo di queste probabilità, che si realizza in $\mu = \mu_0$:
\begin{align*}
	\overline{\alpha} (x_1, \dots, x_n)
	= & P_{\mu_0} \left( \overline{X} - \mu_0 > \overline{x} - \mu_0 \right)       \\
	= & P_{\mu_0} \left( \frac{\overline{X} - \mu_0}{\sigma} \cdot \sqrt{n} >
	\sqrt{n} \cdot \frac{\overline{x} - \mu_0}{\sigma} \right)                     \\
	= & P \left( Z > \sqrt{n} \cdot \frac{\overline{x} - \mu_0}{\sigma} \right)    \\
	= & 1 - \Phi \left( \sqrt{n} \cdot \frac{\overline{x} - \mu_0}{\sigma} \right)
\end{align*}

\subsubsection{Calcolo della curva operativa}
Procediamo ora al calcolo della curva operativa e otteniamo
\begin{align*}
	\beta(\mu) = & P_\mu \left( \frac{\sqrt{n}}{\sigma} \cdot (\overline{X} - \mu_0) \leq
	q_{1-\alpha} \right)                                                                        \\
	=            & \Phi \left( \sqrt{n} \cdot \frac{\mu_0 - \mu}{\sigma} + q_{1-\alpha} \right)
\end{align*}