\part{Calcolo delle probabilità}

\chapter{Prime definizioni}
Il calcolo delle \textbf{probabilità} ci serve per la costruzione di un modello
\textbf{statico inferenziale}, il quale unisce statistica descrittiva e probabilità per descrivere la
realtà.

Prima di addentrarci nei formalismi matematici introduciamo qualche concetto \emph{primitivo}.
\begin{itemize}
	\item Quello che vogliamo calcolare è la probabilità che un certo \textbf{evento} accada. Il concetto
	      di evento non si può formalizzare, ma possiamo fare qualche esempio: se lanciamo un dado, il
	      fatto che esca 6 è un evento.
	\item Il secondo concetto è quello di \textbf{casuale} o \textbf{aleatorio} (\textbf{stocastico}).
	      Queste tre parole hanno quasi lo stesso significato ma possiamo generalizzare dicendo che
	      significano \emph{"dovuto al caso"}. Più avanti introdurremo altri termini come
	      \emph{variabili aleatorie} e \emph{indipendenza stocastica}.
\end{itemize}
Due dei problemi che andremo a trattare sono:
\begin{itemize}
	\item La \textbf{rappresentazione} degli eventi.
	\item Quali \textbf{proprietà} devono soddisfare le probabilità.
\end{itemize}
Noi possiamo vedere tutti gli eventi possibili come un insieme, detto \textbf{spazio dei campioni} o
\textbf{universo}, che indicheremo con $\Omega$.
\begin{itemize}
	\item $\emptyset$, $\Omega$ sono eventi.
	\item Se $A$ e $B$ sono eventi, lo sono anche $A \cup B$ (rappresenta un \verb|or| logico di eventi),
	      $A \cap B$ (rappresenta un \verb|and| logico di eventi) e $A^c$ (rappresenta un \verb|not| logico
	      di eventi). Questi possono essere sottoinsiemi di $\Omega$ o $\Omega$ stesso.
\end{itemize}

\begin{example}
	Lanciamo un dado
	\[ \Omega = \{ 1, 2, 3, 4, 5, 6 \} \]
	L'insieme degli eventi tali che il numero uscito sia
	\begin{itemize}
		\item Pari $A = \{ 2, 4, 6 \}$
		\item Maggiore di 3 $B = \{ 4, 5, 6 \}$
		\item Non pari $A^c = \{ 1, 3, 5 \}$
		\item Pari o maggiore di 3 $A \cup B = \{ 2, 4, 5, 6 \}$
		\item Pari e maggiore di 3 $A \cap B = \{ 4, 6 \}$
	\end{itemize}
\end{example}

\begin{definition}
	Quando c'è un insieme di eventi $\A$ con queste proprietà:
	\begin{itemize}
		\item $\emptyset, \Omega \in \A$
		\item Se $A \in \A$ allora $A^c \in \A$
		\item Se $A, B \in \A$ allora $(A \cup B) \in \A$ e $(A \cap B) \in \A$
	\end{itemize}
	questo è chiamato \textbf{algebra di parti}.
\end{definition}

\begin{definition}[Provvisoria]
	Definiamo la \textbf{probabilità} come una funzione
	\[ P : \A \to [0, 1] \]
	tale che
	\begin{itemize}
		\item $P (\Omega) = 1$.
		\item $A \cap B = \emptyset$ allora $P(A \cup B) = P(A) + P(B)$.
	\end{itemize}
	Una funzione con queste proprietà è detta \emph{finitamente additiva}.
\end{definition}

Vediamo alcune conseguenze di questa definizione
\begin{itemize}
	\item $P(\emptyset) = 0$
	\item $P(A^c) = 1 - P(A)$
	\item Se $B \subseteq A$ e consideriamo $A \backslash B = A \cap B^c$ allora
	      \[ P(A \backslash B) = P(A) - P(B) \]
	\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\end{itemize}
Ancora qualche definizione
\begin{itemize}
	\item Se $P(A) = 0$ si dice che $A$ è un evento \textbf{trascurabile}.
	\item Se $P(A) = 1$ si dice che $A$ è un evento \textbf{quasi certo}.
\end{itemize}
Introduciamo anche un altro concetto, ossia quello di \textbf{additività numerabile} o
$\sigma$-\textbf{additività}, necessaria per \emph{andare al limite} (sarà chiaro più avanti), senza la
quale non si potrebbe fare calcolo statistico. Se consideriamo una successione di eventi a due a due
disgiunti del tipo
\[ A_1, \; A_2, \; A_3, \; \dots \]
con $A_i \cap A_j = \emptyset$ se $i \neq j$ allora deve valere
\[
	P(\cup_{n=1}^\infty A_n) = \sum_{n=1}^\infty P(A_n) =
	\lim_{n \to \infty} \sum_{k=1}^n P(A_k) = 	\lim_{n \to \infty} P(A_1) + \dots + P(A_n)
\]
Questa è detta \textbf{somma infinita}.

\begin{definition}
	Definiamo la \textbf{probabilità} come la funzione $P$ definita sugli eventi
	\[ P : eventi \to [0, 1] \]
	dove $P(\Omega) = 1$ e
	\[ P(\cup_{n=1}^\infty A_n) = \sum_{n=1}^\infty P(A_n) \]
\end{definition}

Siamo ora in grado di capire meglio cosa significa \emph{andare al limite}. Sia
$A_1 \subseteq A_2 \subseteq A_3 \dots$ una successione di eventi, abbiamo che l'evento $A$ definito come
l'unione infinita della successione, equivale a
\[ A = \cup_{n=1}^\infty A_n = \lim_{n \to \infty} A_n \]
Vale quindi che la probabilità che $A$ si verfichi equivale a
\[ P(A) = \lim_{n \to \infty} P(A_n) \]
Il punto di partenza è il caso in cui $\Omega$ è finito ed è quindi definito come segue
\[ \Omega = \{ \omega_1, \dots, \omega_n \} \]
e dunque possiamo prendere come probabilità la funzione finitamente additiva definita su tutto lo spazio
degli eventi tale che $P(\Omega) = 1$. In particolare, quando $\Omega$ è finito allora la probabilità si
può sempre definire su tutti i suoi sottoinsiemi, come la somma della probabilità dei punti che lo
costituiscono
\[ P(A) = \sum_{\omega_i \in A} P(\omega_i) = \sum_{\omega_i \in A} p_i \]
Se invece $\Omega$ è infinito ma numerabile, per esempio $\Omega = \N$. Quando $\Omega$ è numerabile allora
la probabilità si può definire su tutti i sottoinsiemi di $\Omega$ e basta conoscere la probabilità dei
singoli punti $p_i$
\[ p_i = P(\omega_i) \]
e deve valere
\[ \sum_{i=1}^\infty p_i = 1 \]
mentre se consideriamo un sottoinsieme $A$ di $\Omega$ allora vale
\[ P(A) = \sum_{\omega \in A} p_i \]
Se invece $\Omega$ è finito e tutti i suoi punti sembrano ragionevolmente equiprobabili, allora vale
\[ P(\omega_i) = \frac{1}{n} \]
Questa è chiamata \textbf{distribuzione uniforme} di probabilità e vale
\[ P(A) = \frac{\# A}{\# \Omega} = \frac{\text{casi favorevoli}}{\text{casi possibili}} \]
Se $\Omega$ è infinito non possiamo parlare di distribuzione uniforme.
