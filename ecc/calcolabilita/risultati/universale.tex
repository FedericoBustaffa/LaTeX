\section{Formalismo universale}
Supponiamo ora di avere a disposizione un formalismo
\textbf{universale}, in grado cioè di esprimere \emph{tutte}
le funzione calcolabili. Questo sarebbe così potente da
riuscire ad esprimere l'interprete dei propri programmi.

\begin{theorem}[Enumerazione] \label{th: enum}
	Esiste una funzione numerabile parziale $\varphi_z(i, x)$
	tale che $\forall i,x$ vale
	\[ \varphi_i(x) = \varphi_z (i, x) \]
	\begin{proof}
		Poiché la funzione $U(\mu y . T(i, x, y))$ usata nel
		\hyperref[th: fn]{teorema di forma normale} è definita
		per composizione e $\mu$-ricorsione a partire da
		funzioni ricorsive primitive, essa stessa è una una
		funzione calcolabile in due argomenti $i$ e $x$. Avrà
		quindi un indice che chiamiamo $z$ e per cui vale
		\[ \varphi_z (i, x) = U(\mu y. T(i, x, y)) \]
		Applichiamo quindi il teorema di forma normale per
		ottenere
		\[ U(\mu y . T(i, x, y)) = \varphi_i (x) \]
		da qui otteniamo la tesi per transitività
		dell'uguaglianza
		\[
			\varphi_z (i, x) = U(\mu y . T(i, x, y)) =
			\varphi_i (x)
		\]
		Più informalmente la macchina $M_z$ recupera la
		descrizione della macchina $M_i$ e la applica a $x$.
	\end{proof}
\end{theorem}

Il teorema, scritto in forma molto compatta, in sostanza ci
dice che esiste un algoritmo (o una MdT) $z$ che prende in
input un altro algoritmo (o MdT) $i$, i dati $x$ su cui lavora
$i$ e restituisce lo stesso risultato dell'algoritmo $i$-esimo
applicato a $x$. In genere la macchina di Turing $z$ viene
chiamata \textbf{macchina di Turing universale}. In realtà
esistono un'infinità numerabile di MdT universali.

\subsection{Costruzione di una MdT universale}
Proviamo ora a costruire una MdT universale a tre nastri per
riuscire ad avere una visione più concreta di ciò di cui stiamo
parlando. Lo facciamo anche per riuscire ad apprezzare meglio la
differenza tra \emph{sintassi} e \emph{semantica} ed inoltre
tale costruzione ci tornerà utile più avanti per lo studio della
complessità.

Se ci pensiamo un attimo, un qualsiasi calcolatore fisico è una
macchina di turing universale, in quanto prende i nostri
programmi e li esegue ritornando lo stesso risultato che
darebbero se fossero eseguiti a mano da un operatore umano.

Come abbiamo appena visto, i teoremi di
\hyperref[th: fn]{forma normale} e di
\hyperref[th: enum]{teorema di enumerazione} ci forniscono una
prova dell'esistenza di una MdT universale, noi ora vogliamo
costruirne una.

Chiariamo che avere tre nastri non aumenta in alcun modo né la
capacirtà espressiva né le prestazioni della macchina. Serve
solo a noi per riuscire a scrivere il programma più comodamente.

\subsubsection{Codifica}
Supponiamo di avere i seguenti insiemi ausiliari
\begin{gather*}
	Q_* = \{ q_0, q_1, \dots \} \\
	\Sigma_* = \{ \sigma_0, \sigma_1, \dots \}
\end{gather*}
con $h \notin Q_*$ e $L, R, - \notin \Sigma_*$. In questo modo
ogni MdT $M_k$ avrà l'insieme degli stati $Q_k$ e l'insieme dei
simboli $\Sigma_k$ inclusi rispettivamente in $Q_*$ e $\Sigma_*$.

Il prossimo passo consiste nel rappresentare gli elementi di
$Q_*$ e $\Sigma_*$ come stringhe generate dalla concatenazione
del simbolo $\mid$. Vogliamo quindi definire una funzione di
codifica
\[
	\kappa : Q_* \cup \{ h \} \cup \Sigma_* \cup \{ L, R, - \}
	\rightarrow \{ \mid \}^*
\]
in grado di codificare stati e simboli della nostra MdT in
questo modo:
\begin{gather*}
	q_i \mapsto \mid^{i+2}      \quad h \mapsto \mid \\
	\sigma_i \mapsto \mid^{i+4} \quad L \mapsto \mid \quad
	R \mapsto \mid \mid \quad - \mapsto \mid \mid \mid
\end{gather*}
Il motivo per cui $q_i \mapsto \mid^{i+2}$ è che abbiamo già $h$
codificato come $\mid$ e dunque, partendo da $q_0$ abbiamo che
$q_0 \mapsto \mid^2 = \mid \mid$. Discorso analogo per la
codifica dei simboli.

\`E immediato notare però che la funzione $\kappa$ non è
biunivoca in quanto sia $h$ che $L$ vengono codificati in $\mid$
(così come tanti altri stati e simboli che condividono la stessa
codifica). In realtà a noi interessa considerare $\kappa$
ristretta all'insieme di appartenenza dell'oggetto che vogliamo
codificare. Ecco che la funzione diventa biunivoca se, tramite
l'aggiunta di una marca $c$, separiamo la codifica dei vari
insiemi, consideriamo solo quello di interesse. Passiamo adesso
a fissare una MdT
\[ M = (Q, \Sigma, \delta, s) \]
con $s$ stato iniziale e cerchiamo di codificarla andando per
prima cosa ad ordinare l'insieme degli stati
\[ Q = \{ q_{i_1}, \dots, q_{i_k} \} \]
e l'insieme dei simboli
\[ \Sigma = \{ \sigma_{j_1}, \dots, \sigma_{j_k} \} \]
in modo tale che
\[
	p \leq p' \implies i_p \leq i_{p'} \quad
	\land \quad j_p \leq j_{p'}
\]
Consideriamo ora l'alfabeto $\{ \mid, c, d, \#, \start \}$ sotto
l'ipotesi che l'intersezione tra questo e $\Sigma_* \cup Q_*$
sia vuota. La codifica di ogni $n$-upla avviene in questo modo
\[
	S_{p,q} = c \; \kappa (q_{i_p})
	\; c \; \kappa (\sigma_{j_q})
	\; c \; \kappa (q)
	\; c \; \kappa (\sigma)
	\; c \; \kappa (D) \; c
\]
se $\delta (q_{i_p}, \sigma_{j_q}) = (q, \sigma, D)$. Completiamo
con la codifica dei casi in cui $\delta$ non è definita:
\[
	S_{p,q} = c \; \kappa (q_{i_p})
	\; c \; \kappa (\sigma_{j_q})
	\; c \; d \; c \; d \; c \; d \; c
\]
se $\delta(q_{i_p}, \sigma_{j_q})$ non è definita.

\begin{example}
	Vediamo un esempio che applica la codifica appena descritta
\end{example}

Torniamo a noi e cerchiamo di definire una funzione $\rho$ che
mandi una generica MdT $M$ in una stringa fatta di soli caratteri
$\mid$, $c$ e $d$ che verrà racchiusa tra due $c$. Ciò che ci
manca è sapere quale sia lo stato iniziale di $M$ che
codificheremo e prefiggeremo alla codifica della funzione di
transizione $\delta$, nel modo seguente:
\[
	\rho (M) = c \; \kappa (s) \; c \;
	S_{1,1} S_{1,2} \dots
	S_{1,l} S_{2,1} \dots S_{2,l} \dots
	S_{k,1} S_{k,2} \dots S_{k,l} \; c
\]
In questo modo abbiamo generato una stringa da cui è possibile
tornare indietro o ad una MdT o ad un qualcosa che non lo è in
caso la stringa non sia l'immagine di una MdT.

Siamo riusciti a codificare la MdT $M$ ma non abbiamo ancora
finito in quanto ci serve anche la codifica del dato
$w = \sigma'_0 \dots \sigma'_n$ in ingresso. L'ultimo passo
della codifica è ottenuto tramite la funzione $\tau$ che ci
permette di ottenere
\[ \rho(M) \tau(w) \]
ossia la codifica completa della macchina e del suo input. Dove
la funzione $\tau$ è definita come segue
\[
	\tau(\sigma'_0 \dots \sigma'_n) =
	c \; \kappa(\sigma'_0) \;
	c \; \kappa(\sigma'_n) \; c
\]
Si noti che tre $c$ separano la codifica di $M$ da quella $w$.

\subsubsection{Esecuzione}
Quello che vogliamo dalla MdT universale
\[ U = (Q_U, \Sigma_U, \delta_U, s_U) \]
è che per ogni $M$ e per ogni $w \in \Sigma^*$ succeda che
\begin{itemize}
	\item Se $M$ termina su $w$ e da come risultato $uav$
	      \[
		      (s, \underline{\start}, w) \rightarrow^*_0
		      (h, u \underline{a} v)
	      \]
	      allora $U$ termina su $\rho(M) \tau(w)$ e il nastro è
	      la codifica di $uav$
	      \[
		      (s_U, \underline{\start} \rho(M) \tau(w))
		      \rightarrow^*_U (h, \tau(uav) \underline{\#})
	      \]
	\item Viceversa se $U$ termina su $\rho(M) \tau(w)$ e da come
	      risultato $u'a'v'$
	      \[
		      (s_U, \underline{\start} \rho(M) \tau(w))
		      \rightarrow^*_U (h, u' \underline{a'}v')
	      \]
	      allora $a' = \#$ è il bianco, $v' = \epsilon$ è la
	      marca di fine stringa e $u' = \tau(uav)$ è la codifica
	      di $uav$ per quale $u$, $a$ e $v$ tali che $M$ termina
	      su $w$ e da come risultato $uav$
	      \[
		      (s, \underline{\start}, w) \rightarrow^*_0
		      (h, u \underline{a} v)
	      \]
\end{itemize}
Nella nostra MdT universale abbiamo che nel primo nastro c'è la
codifica $\tau(w)$ di $w$, nel secondo nastro la codifica di
$\rho(M)$ di $M$ e nel terzo c'è la codifica dello stato in cui
si trova $M$.

Ovviamente, prima di iniziare il calcolo, la MdT universale deve
attraversare una fase di inizializzazione in cui scrive sui vari
nastri le codifiche di $M$, $w$ ed $s$.

Dopo la fase di inizializzazione passiamo a descrivere coem
avviene la fase di calcolo. Dato che abbiamo tre nastri, per
simplicità chiameremo cursore $i$ (con $i = \{ 1, 2, 3\}$) il
cursore sull'$i$-esimo nastro. Iniziamo con il calcolo:
\begin{enumerate}
	\item Se il terzo nastro (quello con lo stato) contiene la
	      codifica di $q_{h_i}$, allora spostiamo il cursore $2$
	      sul primo carattere della stringa che codifica $M$.
	\item Se il cursore $1$ è all'inizio di
	      $\kappa(\sigma_{k_j})$, allora spostiamo il cursore
	      $2$ sulla "quitupla" $S_{i,j}$.
	\item Se
	      \[
		      S_{i,j} = c \; \mid^p \; c \; \mid^q \; c \;
		      \mid^{p'} \; c \; \mid^{q'} \; c \; \mid^r \; c
	      \]
	      \begin{itemize}
		      \item Si scrive sul terzo nastro $\mid^{p'}$ al
		            posto di $\kappa(q_{h_i})$.
		      \item Si scrive $\mid^{q'}$ sul primo nastro al
		            posto di $\kappa(\sigma_{k_j})$,
		            eventualmente spostando a destra o a
		            sinistra la porzione di nastro a destra di
		            $\kappa(\sigma_{k_j})$, a seconda che la
		            lunghezza sia minore o maggiore di quella di
		            $\mid^{q'}$.
		      \item Si sposta il cursore $1$ al precedente o
		            al successivo gruppo $c \; \mid^v \; c$,
		            oppure lo si lascia dov'è a seconda del
		            valore di $r$.
	      \end{itemize}
	      Se
	      \[
		      S_{i,j} = c \; \mid^p \; c \; \mid^q \;
		      c \; d \; c \; d \; c \; d \; c
	      \]
	      abbiamo una condizione di terminazione con
	      \textbf{errore}. Se invece
	      \[
		      S_{i,j} = c \; \mid^p \; c \; \mid^q \; c \;
		      \mid \; c \; \mid^{p'} \; c \; \mid^j \; c
	      \]
	      abbiamo una condizione di terminazione con
	      \textbf{successo}.
\end{enumerate}
Se non fosse chiaro, un paragone con il comportamento di un
classico interprete potrebbe chiarire alcuni concetti:
\begin{itemize}
	\item I primi due passi corrispondono al \verb|fetch|
	      dell'istruzione. Attraverso il contenuto del terzo
	      nastro e mediante il simbolo corrente si realizza
	      il \verb|program counter|.
	\item L'ultimo passo incorpora la decodifica dell'istruzione
	      corrente e l'esecuzione vera e propria di quest'utima,
	      con relativa memorizzazione del risultato. Questo se
	      l'istruzione decodificata non è un errore o
	      l'istruzione di fine esecuzione.
\end{itemize}

% ----
Passiamo ora ad un teorema che possiamo vedere un po' come il
duale del teorema di enumerazione. Enunceremo una prima versione
semplificata e poi la sua forma generale.

\begin{theorem}[Teorema del parametro s-1-1]
	\label{th: s-1-1}
	Esiste una funzione $s$ calcolabile totale e iniettiva tale
	che per ogni $i$, $x$ e $y$ vale
	\[ \lambda y . \varphi_i (x, y) = \varphi_{s (i, x)} (y) \]
	\begin{proof}
		Iniziamo con il definire due passi:
		\begin{enumerate}
			\item Da $i$ prendiamo l'$i$-esima MdT.
			\item Scriviamo sul nastro di $M_i$ l'input $x$ e
			      $y$.
		\end{enumerate}
		Questi due passi definiscono un algoritmo il quale ha
		indice $j$ per la tesi di Church-Turing. Tale indice
		identifica la macchina che calcola
		\[ \varphi_{s(i,x)} \]
		vale cioè
		\[ j = s(i, x) \]
		A questo punto dobbiamo evitare di trovarci nella
		situazione in cui
		\[ s(i, x) = s(i, x') \]
		abbiamo quindi bisogno di una funzione per effettuare la
		ricerca dell'indice $j$ che sia iniettiva. Per il
		\hyperref[th: padding lemma]{padding lemma} sappiamo che
		esiste un'infità numerabile di algoritmi che calcolano
		la stessa funzione e dunque cerchiamo $h$ maggiore di
		tutti i valori ottenuti fino ad ora. Otteniamo così una
		funzione strettamente crescente e quindi iniettiva.
	\end{proof}
\end{theorem}

Come possiamo notare nella prima funzione abbiamo due argomenti
e nella seconda uno solo. Il fatto è che quando $x$ viene
considerato come un \emph{parametro}, allora è possibile
calcolare la prima funzione utilizzando un altra macchina a
partire dall'indice $i$.

\begin{example}
	Prendiamo ad esempio la funzione
	\[ x + y \]
	Una volta fissata la $x$ ad un certo valore, supponiamo
	$2$, la $x$ a questo punto non è più un argomento ma
	diventa un parametro. A questo punto la funzione
	\[ 2 + y \]
	può essere calcolata da un'altra macchina che a regola
	dovrebbe essere un po' più efficiente di quella di partenza.
\end{example}

Questo sta alla base della \textbf{valutazione parziale} che è
molto utile in quei contesti in cui si vuole mantenere un alto
livello di generalizzazione.

\begin{theorem}[Teorema del parametro s-m-n]
	\label{th: s-m-n}
	Per ogni $m, n \geq 0$ esiste una funzione calcolabile
	totale (iniettiva) $s_n^m$ con $m+1$ argomenti, tale che
	per ogni $x, y_1, \dots, y_m$, vale
	\[
		\varphi_{s_n^m (x, y_1, \dots, y_m)}^{(n)} =
		\lambda z_1, \dots, z_n .
		\varphi_x^{(m+n)} (y_1, \dots, y_m, z_1, \dots, z_n)
	\]
\end{theorem}

Si noti come il teorema del parametro e quello di enumerazione
siano in un certo senso l'inverso l'uno dell'altro. Infatti
l'uno "abbassa" un argomento nella posizione di indice, mentre
l'altro "innalza" un indice nella posizione di argomento.

\begin{theorem}[Espressività]
	Un formalismo è \textbf{Turing-equivalente}, ossia calcola
	tutte e sole le funzioni T-calcolabili ed è universale, se
	e solo se
	\begin{itemize}
		\item Ha un algoritmo universale (vale cioè il teorema
		      di enumerazione).
		\item Vale il teorema del parametro.
	\end{itemize}
\end{theorem}

Grazie al teorema del parametro si dimostra un altro teorema
che ha un ruolo fondamentale sia in informatica che in teoria
della calcolabilità.

\begin{theorem}[Punto fisso] \label{th: punto_fisso}
	Per ogni funzione $f$ calcolabile totale $\exists n$ tale
	che
	\[ \varphi_n = \varphi_{f(n)} \]
	\begin{proof}
		Definiamo la seguente funzione calcolabile "diagonale"
		\[
			\psi (u, z) = \varphi_{d(u)} (z) =
			\begin{cases}
				\varphi_{\varphi_u (u)} (z) &
				\text{se } \varphi_u (u) \downarrow \\
				\text{indefinita}           &
				\text{altrimenti}
			\end{cases}
		\]
		Per il teorema del parametro, $d(u)$ è totale e
		iniettiva (e non dipende da $f$). Data $f$, allora
		anche $f \circ d$ è calcolabile e sia $v$ proprio
		un indice tale che
		\[ \varphi_v(x) = f(d(x)) \]
		Tale funzione è totale (perché sia $d$ che $f$ lo sono)
		e quindi $\varphi_v (v)$ converge. Pertanto, in accordo
		con la definizione data in precedenza di $\psi (u,z)$
		abbiamo che
		\[ \varphi_{d(v)} = \varphi_{\varphi_v(v)} \]
		Calcoliamo ora $d(v)$ e supponiamo che il risultato sia
		$n$, cioè poniamo
		\[ n = d(v) \]
		Dimostriamo che è un punto fisso di $f$. Infatti vale
		la seguente catena di eguaglianze
		\[
			\varphi_n  = \varphi_{d(v)}
			= \varphi_{\varphi_v (v)}
			= \varphi_{f(d(v))}
			= \varphi_{f(n)}
		\]
		Nell'eguaglianza più a sinistra si sfrutta l'iniettività
		che viene garantita dal teorema del parametro.
	\end{proof}
\end{theorem}

Un tale indice viene detto \textbf{punto fisso} di $f$. Il
teorema inoltre ci dice che la funzione $f$ trasforma algoritmi
in algoritmi, proprio come fa un compilatore.

In altre parole il punto fisso non cambia la funzione calcolata
ma trasforma l'algoritmo $P_n$ nell'algoritmo $P_{f(n)}$ con la
stessa semantica.

\begin{property}
	Nelle ipotesi del teorema di ricorsione
	\begin{itemize}
		\item Il punto fisso è calcolabile mediante una funzione
		      totale (iniettiva) $g$ a partire dall'indice di
		      $f$.
		\item Ci sono $\# (\N)$ punti fissi di $f$.
	\end{itemize}
\end{property}

\begin{proof}
	Per dimostrare il primo punto prendiamo $h(x)$
	calcolabile totale tale che $\forall n$ vale
	\[ \varphi_{h(x)} (n) = \varphi_x (d(n)) \]
	Allora vale
	\[ g(x) = d(h(x)) \]
	Il secondo punto segue invece dal teorema
	\ref{th: n calc}.
\end{proof}

C'è anche un altro modo per dimostrare il teorema del punto
fisso, o meglio per specificare come deve essere implementata
la ricorsione nei linguaggi di programmazione.

Supponiamo di avere una procedura ricorsiva $P$ il cui corpo
sia $C$, all'interno del quale ovviamente compare la chiamata
a $P$ stessa.